{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "[The source of code](https://www.kaggle.com/code/unmoved/classify-possum-population)",
   "id": "89dd995e9c02711c"
  },
  {
   "cell_type": "markdown",
   "id": "f3ec8509",
   "metadata": {
    "id": "f28d7e7b",
    "papermill": {
     "duration": 0.014922,
     "end_time": "2024-12-30T07:28:53.971174",
     "exception": false,
     "start_time": "2024-12-30T07:28:53.956252",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Company Name:**\n",
    "- OpenIntro Statistics Book\n",
    "\n",
    "**Problem Type:**\n",
    "- Binary Classification\n",
    "\n",
    "**Problem:**\n",
    "- Can you use your skills to predict the age of a possum, its head length, whether it is male or female?\n",
    "\n",
    "**Goal:**\n",
    "- We will be trying to determine the population as either Victoria or other (New South Wales or Queensland) based on the features provided.\n",
    "- These details (features we will use to predict) are as follows:\n",
    "  - case = observation number\n",
    "  - site = The site number where the possum was trapped.\n",
    "  - sex = Gender, either m (male) or f (female).\n",
    "  - age = Age of possum\n",
    "  - hdlngth = Head length, in mm.\n",
    "  - skullw = Skull width, in mm.\n",
    "  - totlngth = Total length, in cm.\n",
    "  - taill = Tail length, in cm.\n",
    "  - footlgth = foot length\n",
    "  - earconch = ear conch length\n",
    "  - eye = distance from medial canthus to lateral canthus of right eye\n",
    "  - chest = chest girth (in cm)\n",
    "  - belly = belly girth (in cm)\n",
    "  \n",
    "  \n",
    "- Which will let us determine the target variable which is:\n",
    "  - Pop = Population, either Vic (Victoria) or other (New South Wales or Queensland)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2693cdfb",
   "metadata": {
    "papermill": {
     "duration": 0.011962,
     "end_time": "2024-12-30T07:28:53.995596",
     "exception": false,
     "start_time": "2024-12-30T07:28:53.983634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# UNMOVED TEMPLATE GUIDE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa122f2e",
   "metadata": {
    "papermill": {
     "duration": 0.01198,
     "end_time": "2024-12-30T07:28:54.019887",
     "exception": false,
     "start_time": "2024-12-30T07:28:54.007907",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"border:3px solid #FFD700; padding: 15px; border-radius: 15px; background-color: #FFFACD;\">\n",
    "    <h3 style=\"color: #DAA520; text-align: center;\"><a href=\"https://www.kaggle.com/unmoved\" style=\"color: #DAA520; text-decoration: none;\">Unmoved's Template Guide</a></h3>\n",
    "    <p style=\"font-size: 15px; color: #333333; text-align: center;\">\n",
    "        Hey, I'm <strong><a href=\"https://www.kaggle.com/unmoved\" style=\"color: #0000EE;\">Unmoved</a></strong>, and this is my template. \n",
    "    </p>\n",
    "    <p style=\"font-size: 15px; color: #333333; text-align: center;\">\n",
    "        Please ensure to change these variables inside of the <strong>SET IMPORTANT VARIABLES</strong> section of this notebook before proceeding.\n",
    "    </p>\n",
    "    <p style=\"font-size: 15px; color: #333333; text-align: center;\">\n",
    "        If you use my template, please be sure to keep this text in your notebook to credit me.\n",
    "    </p>\n",
    "    <h3 style=\"color: #DAA520;\">Basics</h3>\n",
    "    <ul style=\"font-size: 14px; color: #333333;\">\n",
    "        <li><strong>seed_value</strong>: For reproducibility</li>\n",
    "        <li><strong>problem_type</strong>: 'classify' or 'regress' depending on your task.</li>\n",
    "        <li><strong>target_column</strong>: The target column in your dataset.</li>\n",
    "        <li><strong>load_from_file</strong>: Load data from a CSV file or generate sample data.</li>\n",
    "        <li><strong>file_name</strong>: Provide the name of the CSV file if loading data from a file.</li>\n",
    "        <li><strong>desired_samples</strong>: \n",
    "            <ul>\n",
    "                <li>Controls the total number of samples to generate if not loading from a file.</li>\n",
    "                <li>Determines the number of samples retained after undersampling if applicable.</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><strong>do_undersample_data</strong>: Controls if you want to undersample your data (will preserve balance class distribution if classification), regardless if it was loaded or generated. The <strong>desired_samples</strong> parameter will control the number of samples retained.</li>\n",
    "        <li><strong>show_eda</strong>: Decide whether to display EDA (Exploratory Data Analysis).</li>\n",
    "    </ul>\n",
    "    <h3 style=\"color: #DAA520;\">Cross Validation</h3>\n",
    "    <ul style=\"font-size: 14px; color: #333333;\">\n",
    "        <li><strong>n_folds</strong>: Set the number of folds for cross-validation. This setting applies to everything that uses cross-validation in the notebook.</li>\n",
    "    </ul>\n",
    "    <h3 style=\"color: #DAA520;\">Genetic Algorithm and Model Loading Settings</h3>\n",
    "    <ul style=\"font-size: 14px; color: #333333;\">\n",
    "        <li><strong>load_existing_model</strong>: Load an existing model from the current directory. Remember, the code saves the model after making by default, so will use the same model unless you delete it.</li>\n",
    "        <li><strong>model_name</strong>: The name to save the new model as, or the name to try loading the existing model as.</li>\n",
    "        <li><strong>categorical_threshold</strong>: Adjust the threshold for treating a column as categorical.</li>\n",
    "        <li><strong>n_population</strong>: Adjust the population size for the genetic algorithm.</li>\n",
    "        <li><strong>n_generations</strong>: Set the number of generations for the genetic algorithm.</li>\n",
    "        <li><strong>cxpb</strong>: Modify the crossover probability for the genetic algorithm.</li>\n",
    "        <li><strong>mutpb</strong>: Adjust the mutation probability for the genetic algorithm.</li>\n",
    "    </ul>\n",
    "    <h3 style=\"color: #DAA520;\">Permutation Feature Importance Settings</h3>\n",
    "    <ul style=\"font-size: 14px; color: #333333;\">\n",
    "        <li><strong>get_permutation_importance</strong>: Decide whether to show permutation importance.</li>\n",
    "        <li><strong>n_repeats</strong>: Set the number of times to repeat the permutation importance calculation. This will be validated by the same number of folds in n_folds.</li>\n",
    "    </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4c80d2",
   "metadata": {
    "papermill": {
     "duration": 0.012655,
     "end_time": "2024-12-30T07:28:54.046023",
     "exception": false,
     "start_time": "2024-12-30T07:28:54.033368",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# INITIALIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4914ff12",
   "metadata": {
    "papermill": {
     "duration": 0.012468,
     "end_time": "2024-12-30T07:28:54.070967",
     "exception": false,
     "start_time": "2024-12-30T07:28:54.058499",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## INSTALLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da9837a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T22:05:40.882760Z",
     "start_time": "2024-08-26T22:05:38.164266Z"
    },
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-12-30T07:28:54.099815Z",
     "iopub.status.busy": "2024-12-30T07:28:54.099077Z",
     "iopub.status.idle": "2024-12-30T07:29:10.514564Z",
     "shell.execute_reply": "2024-12-30T07:29:10.512642Z"
    },
    "papermill": {
     "duration": 16.433843,
     "end_time": "2024-12-30T07:29:10.517757",
     "exception": false,
     "start_time": "2024-12-30T07:28:54.083914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: If you get a cant find _C error, try simply restarting the notebook, otherwise you may need to manually ensure these are installed\n",
      "\n",
      "'numpy' is already installed.\n",
      "'pandas' is already installed.\n",
      "'psutil' is already installed.\n",
      "'joblib' is already installed.\n",
      "'deap' is already installed.\n",
      "'torch' is already installed.\n",
      "'sklearn' is already installed.\n",
      "'xgboost' is already installed.\n",
      "'catboost' is already installed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       ".datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,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');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'lightgbm' is already installed.\n",
      "'plotly' is already installed.\n",
      "'IPython' is already installed.\n",
      "'sweetviz' not found, installing...\n",
      "Collecting sweetviz\n",
      "  Downloading sweetviz-2.3.1-py3-none-any.whl (15.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 15.1/15.1 MB 64.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from sweetviz) (1.21.6)\n",
      "Requirement already satisfied: importlib-resources>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from sweetviz) (5.10.2)\n",
      "Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3 in /opt/conda/lib/python3.7/site-packages (from sweetviz) (1.3.5)\n",
      "Requirement already satisfied: tqdm>=4.43.0 in /opt/conda/lib/python3.7/site-packages (from sweetviz) (4.64.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.7/site-packages (from sweetviz) (1.7.3)\n",
      "Requirement already satisfied: jinja2>=2.11.1 in /opt/conda/lib/python3.7/site-packages (from sweetviz) (3.1.2)\n",
      "Requirement already satisfied: matplotlib>=3.1.3 in /opt/conda/lib/python3.7/site-packages (from sweetviz) (3.5.3)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from sweetviz) (6.0.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from importlib-resources>=1.2.0->sweetviz) (3.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2>=2.11.1->sweetviz) (2.1.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.1.3->sweetviz) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.1.3->sweetviz) (23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.1.3->sweetviz) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.1.3->sweetviz) (4.37.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.1.3->sweetviz) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.1.3->sweetviz) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.1.3->sweetviz) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->sweetviz) (2022.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->sweetviz) (4.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib>=3.1.3->sweetviz) (1.16.0)\n",
      "Installing collected packages: sweetviz\n",
      "Successfully installed sweetviz-2.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'tqdm' is already installed.\n",
      "'deap' is already installed.\n",
      "'seaborn' is already installed.\n",
      "'matplotlib' is already installed.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "print(\"Note: If you get a cant find _C error, try simply restarting the notebook, otherwise you may need to manually ensure these are installed\\n\")\n",
    "\n",
    "packages = [\n",
    "    'numpy', 'pandas', 'psutil', 'joblib', 'deap', 'torch', \n",
    "    'sklearn', 'xgboost', 'catboost', 'lightgbm', 'plotly', \n",
    "    'IPython', 'sweetviz', 'tqdm', 'deap', 'seaborn', \n",
    "    'matplotlib'\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"'{package}' is already installed.\")\n",
    "    except ImportError:\n",
    "        print(f\"'{package}' not found, installing...\")\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e0dbaf",
   "metadata": {
    "papermill": {
     "duration": 0.012964,
     "end_time": "2024-12-30T07:29:10.544957",
     "exception": false,
     "start_time": "2024-12-30T07:29:10.531993",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86d53632",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T22:05:41.458268Z",
     "start_time": "2024-08-26T22:05:40.884264Z"
    },
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-12-30T07:29:10.574317Z",
     "iopub.status.busy": "2024-12-30T07:29:10.573867Z",
     "iopub.status.idle": "2024-12-30T07:29:11.542661Z",
     "shell.execute_reply": "2024-12-30T07:29:11.541569Z"
    },
    "papermill": {
     "duration": 0.987504,
     "end_time": "2024-12-30T07:29:11.545583",
     "exception": false,
     "start_time": "2024-12-30T07:29:10.558079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# System \n",
    "import os\n",
    "import sys\n",
    "import psutil\n",
    "import platform\n",
    "import subprocess\n",
    "import time\n",
    "import copy\n",
    "import hashlib\n",
    "import warnings\n",
    "import pickle\n",
    "from itertools import product\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Sample Datasets\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "\n",
    "# Data Splitting and Cross-Validation\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_val_score\n",
    "\n",
    "# Imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Encoders\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "# Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Feature Extraction and Dimensionality Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Feature importance\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# Feature Transforms\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Pipelines and Quality of Life\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin, RegressorMixin\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.utils.validation import check_X_y, check_array\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, StackingClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingRegressor, VotingClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, RidgeClassifierCV, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Regressors\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, StackingRegressor, GradientBoostingRegressor, AdaBoostRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV, LinearRegression, ElasticNet, ElasticNetCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from deap import base, creator, tools, algorithms # For genetic search \n",
    "\n",
    "# Plotting and Visuals\n",
    "import plotly.express as px\n",
    "from IPython.display import IFrame\n",
    "import sweetviz as sv\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.utils import estimator_html_repr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8b7c28",
   "metadata": {
    "papermill": {
     "duration": 0.013392,
     "end_time": "2024-12-30T07:29:11.572396",
     "exception": false,
     "start_time": "2024-12-30T07:29:11.559004",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## GENETIC SEARCH FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "422c8f07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T22:05:41.520241Z",
     "start_time": "2024-08-26T22:05:41.459270Z"
    },
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-12-30T07:29:11.602302Z",
     "iopub.status.busy": "2024-12-30T07:29:11.601886Z",
     "iopub.status.idle": "2024-12-30T07:29:11.676386Z",
     "shell.execute_reply": "2024-12-30T07:29:11.675103Z"
    },
    "papermill": {
     "duration": 0.093309,
     "end_time": "2024-12-30T07:29:11.679107",
     "exception": false,
     "start_time": "2024-12-30T07:29:11.585798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_pipeline_and_genetic_search(X, y, cat_cols, num_cols, problem_type='classify', n_folds=5, n_population=20, n_generations=10, cxpb=0.5, mutpb=0.2):   \n",
    "        \n",
    "    # Numerical transformer with scaling\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    # Categorical transformer\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent', fill_value='missing')),\n",
    "        ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "    ])\n",
    "\n",
    "    # Combine transformers\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, num_cols),\n",
    "            ('cat', categorical_transformer, cat_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Define PCA\n",
    "    pca = PCA()\n",
    "\n",
    "    # Check if GPU is available\n",
    "    gpu_available = torch.cuda.is_available()\n",
    "\n",
    "    if problem_type == 'classify':\n",
    "        model_choices = {\n",
    "            'rf': RandomForestClassifier(verbose=0, n_jobs=-1),\n",
    "            'xgb': XGBClassifier(verbosity=0, n_jobs=-1, device='gpu' if gpu_available else 'cpu'),\n",
    "            'lgbm': LGBMClassifier(verbosity=-1, n_jobs=-1, device='gpu' if gpu_available else 'cpu')\n",
    "        }\n",
    "        cv = StratifiedKFold(n_splits=n_folds)\n",
    "        scoring_metric = 'accuracy'\n",
    "    elif problem_type == 'regress':\n",
    "        model_choices = {\n",
    "            'rf': RandomForestRegressor(verbose=0, n_jobs=-1),\n",
    "            'xgb': XGBRegressor(verbosity=0, n_jobs=-1, device='cuda' if gpu_available else 'cpu'),\n",
    "            'lgbm': LGBMRegressor(verbosity=-1, n_jobs=-1, device='gpu' if gpu_available else 'cpu')\n",
    "        }\n",
    "        cv = KFold(n_splits=n_folds)\n",
    "        scoring_metric = 'r2'\n",
    "\n",
    "    best_estimators = {}\n",
    "    parameter_hashes = {}\n",
    "\n",
    "    # Start a timer\n",
    "    evaluating_start_time = time.time()\n",
    "\n",
    "    for model_name, model in model_choices.items():\n",
    "        print(f\"Optimizing model: {model_name} using Genetic Algorithm\")\n",
    "        \n",
    "        # Define inner functions for evaluation, mutation, and mating\n",
    "\n",
    "        def hash_parameters(params):\n",
    "            \"\"\"Generate a hash for a given set of parameters.\"\"\"\n",
    "            param_str = str(params)\n",
    "            return hashlib.md5(param_str.encode()).hexdigest()\n",
    "\n",
    "        def evaluate_individual_rf(individual):\n",
    "            param_hash = hash_parameters(individual)\n",
    "            if param_hash in parameter_hashes:\n",
    "                print(f\"[rf] Skipping duplicate evaluation: {individual}, score reused: {parameter_hashes[param_hash]:.4f}\")\n",
    "                return parameter_hashes[param_hash],\n",
    "            \n",
    "            (n_estimators, max_depth, min_samples_split, min_samples_leaf, max_features, bootstrap, pca_n_components) = individual\n",
    "            \n",
    "            model.set_params(\n",
    "                n_estimators=int(n_estimators),\n",
    "                max_depth=int(max_depth),\n",
    "                min_samples_split=int(min_samples_split),\n",
    "                min_samples_leaf=int(min_samples_leaf),\n",
    "                max_features=max_features,\n",
    "                bootstrap=bootstrap\n",
    "            )\n",
    "            \n",
    "            pca.n_components = pca_n_components if pca_n_components else None\n",
    "            \n",
    "            pipeline = Pipeline(steps=[\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('pca', pca),\n",
    "                ('model', model)\n",
    "            ])\n",
    "            \n",
    "            scores = cross_val_score(pipeline, X, y, cv=cv, scoring=scoring_metric, n_jobs=-1)\n",
    "            score_mean = scores.mean()\n",
    "            print(f\"[rf] Evaluating: {individual} | Score: {score_mean:.4f}\")\n",
    "            parameter_hashes[param_hash] = score_mean  # Cache the score\n",
    "            return score_mean,\n",
    "\n",
    "        def evaluate_individual_xgb(individual):\n",
    "            param_hash = hash_parameters(individual)\n",
    "            if param_hash in parameter_hashes:\n",
    "                print(f\"[xgb] Skipping duplicate evaluation: {individual}, score reused: {parameter_hashes[param_hash]:.4f}\")\n",
    "                return parameter_hashes[param_hash],\n",
    "            \n",
    "            (n_estimators, max_depth, learning_rate, subsample, colsample_bytree, gamma, \n",
    "             reg_alpha, reg_lambda, pca_n_components) = individual\n",
    "            \n",
    "            model.set_params(\n",
    "                n_estimators=int(n_estimators),\n",
    "                max_depth=int(max_depth),\n",
    "                learning_rate=learning_rate,\n",
    "                subsample=subsample,\n",
    "                colsample_bytree=colsample_bytree,\n",
    "                gamma=gamma,\n",
    "                reg_alpha=reg_alpha,\n",
    "                reg_lambda=reg_lambda\n",
    "            )\n",
    "            \n",
    "            pca.n_components = pca_n_components if pca_n_components else None\n",
    "            \n",
    "            pipeline = Pipeline(steps=[\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('pca', pca),\n",
    "                ('model', model)\n",
    "            ])\n",
    "            \n",
    "            scores = cross_val_score(pipeline, X, y, cv=cv, scoring=scoring_metric, n_jobs=-1)\n",
    "            score_mean = scores.mean()\n",
    "            print(f\"[xgb] Evaluating: {individual} | Score: {score_mean:.4f}\")\n",
    "            parameter_hashes[param_hash] = score_mean  # Cache the score\n",
    "            return score_mean,\n",
    "\n",
    "        def evaluate_individual_lgbm(individual):\n",
    "            param_hash = hash_parameters(individual)\n",
    "            if param_hash in parameter_hashes:\n",
    "                print(f\"[lgbm] Skipping duplicate evaluation: {individual}, score reused: {parameter_hashes[param_hash]:.4f}\")\n",
    "                return parameter_hashes[param_hash],\n",
    "            \n",
    "            (n_estimators, max_depth, learning_rate, num_leaves, min_child_samples, subsample, \n",
    "             colsample_bytree, reg_alpha, reg_lambda, pca_n_components) = individual\n",
    "            \n",
    "            model.set_params(\n",
    "                n_estimators=int(n_estimators),\n",
    "                max_depth=int(max_depth),\n",
    "                learning_rate=learning_rate,\n",
    "                num_leaves=int(num_leaves),\n",
    "                min_child_samples=int(min_child_samples),\n",
    "                subsample=subsample,\n",
    "                colsample_bytree=colsample_bytree,\n",
    "                reg_alpha=reg_alpha,\n",
    "                reg_lambda=reg_lambda\n",
    "            )\n",
    "            \n",
    "            pca.n_components = pca_n_components if pca_n_components else None\n",
    "            \n",
    "            pipeline = Pipeline(steps=[\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('pca', pca),\n",
    "                ('model', model)\n",
    "            ])\n",
    "            \n",
    "            scores = cross_val_score(pipeline, X, y, cv=cv, scoring=scoring_metric, n_jobs=-1)\n",
    "            score_mean = scores.mean()\n",
    "            print(f\"[lgbm] Evaluating: {individual} | Score: {score_mean:.4f}\")\n",
    "            parameter_hashes[param_hash] = score_mean  # Cache the score\n",
    "            return score_mean,\n",
    "\n",
    "        def custom_mutate_rf(individual):\n",
    "            print(f\"[rf] Before mutation: {individual}\")\n",
    "\n",
    "            for i in range(len(individual)):\n",
    "                if i == 0:  # n_estimators, integer mutation\n",
    "                    individual[i] += int(random.gauss(0, 50))  \n",
    "                    individual[i] = max(100, min(1000, int(individual[i])))  \n",
    "                elif i == 1:  # max_depth, integer mutation\n",
    "                    individual[i] += int(random.gauss(0, 5))\n",
    "                    individual[i] = max(10, min(50, int(individual[i])))\n",
    "                elif i == 2:  # min_samples_split, integer mutation\n",
    "                    individual[i] += int(random.gauss(0, 1))\n",
    "                    individual[i] = max(2, min(10, int(individual[i])))  \n",
    "                elif i == 3:  # min_samples_leaf, integer mutation\n",
    "                    individual[i] += int(random.gauss(0, 1))\n",
    "                    individual[i] = max(1, min(10, int(individual[i])))  \n",
    "                elif i == 4:  # max_features, categorical mutation\n",
    "                    individual[i] = random.choice([None, 'sqrt', 'log2'])  \n",
    "                elif i == 5:  # bootstrap, boolean mutation\n",
    "                    individual[i] = random.choice([True, False])\n",
    "                elif i == 6:  # pca_n_components, categorical mutation\n",
    "                    individual[i] = random.choice([None, 0.90, 0.99])\n",
    "\n",
    "            print(f\"[rf] After mutation: {individual}\")\n",
    "            return individual,\n",
    "\n",
    "        def custom_mutate_xgb(individual):\n",
    "            print(f\"[xgb] Before mutation: {individual}\")\n",
    "\n",
    "            for i in range(len(individual)):\n",
    "                if i == 0:  # n_estimators, integer mutation\n",
    "                    individual[i] += int(random.gauss(0, 50))  \n",
    "                    individual[i] = max(100, min(1000, int(individual[i])))  \n",
    "                elif i == 1:  # max_depth, integer mutation\n",
    "                    individual[i] += int(random.gauss(0, 5))\n",
    "                    individual[i] = max(10, min(50, int(individual[i])))\n",
    "                elif i == 2:  # learning_rate, continuous mutation\n",
    "                    individual[i] += random.gauss(0, 0.01)\n",
    "                    individual[i] = max(0.01, min(0.3, individual[i]))\n",
    "                elif i == 3:  # subsample, continuous mutation\n",
    "                    individual[i] += random.gauss(0, 0.1)\n",
    "                    individual[i] = max(0.6, min(1.0, individual[i]))\n",
    "                elif i == 4:  # colsample_bytree, continuous mutation\n",
    "                    individual[i] += random.gauss(0, 0.1)\n",
    "                    individual[i] = max(0.5, min(1.0, individual[i]))\n",
    "                elif i == 5:  # gamma, continuous mutation\n",
    "                    individual[i] += random.gauss(0, 0.1)\n",
    "                    individual[i] = max(0, min(1.0, individual[i]))\n",
    "                elif i == 6:  # reg_alpha, continuous mutation\n",
    "                    individual[i] += random.gauss(0, 1.0)\n",
    "                    individual[i] = max(0, min(10.0, individual[i]))\n",
    "                elif i == 7:  # reg_lambda, continuous mutation\n",
    "                    individual[i] += random.gauss(0, 1.0)\n",
    "                    individual[i] = max(0, min(10.0, individual[i]))\n",
    "                elif i == 8:  # pca_n_components, categorical mutation\n",
    "                    individual[i] = random.choice([None, 0.90, 0.99])\n",
    "\n",
    "            print(f\"[xgb] After mutation: {individual}\")\n",
    "            return individual,\n",
    "\n",
    "        def custom_mutate_lgbm(individual):\n",
    "            print(f\"[lgbm] Before mutation: {individual}\")\n",
    "\n",
    "            for i in range(len(individual)):\n",
    "                if i == 0:  # n_estimators, integer mutation\n",
    "                    individual[i] += int(random.gauss(0, 50))  \n",
    "                    individual[i] = max(100, min(1000, int(individual[i])))  \n",
    "                elif i == 1:  # max_depth, integer mutation\n",
    "                    individual[i] += int(random.gauss(0, 5))\n",
    "                    individual[i] = max(10, min(50, int(individual[i])))\n",
    "                elif i == 2:  # learning_rate, continuous mutation\n",
    "                    individual[i] += random.gauss(0, 0.01)\n",
    "                    individual[i] = max(0.01, min(0.3, individual[i]))\n",
    "                elif i == 3:  # num_leaves, integer mutation\n",
    "                    individual[i] += int(random.gauss(0, 5))\n",
    "                    individual[i] = max(10, min(50, int(individual[i])))\n",
    "                elif i == 4:  # min_child_samples, integer mutation\n",
    "                    individual[i] += int(random.gauss(0, 5))\n",
    "                    individual[i] = max(5, min(100, int(individual[i])))\n",
    "                elif i == 5:  # subsample, continuous mutation\n",
    "                    individual[i] += random.gauss(0, 0.1)\n",
    "                    individual[i] = max(0.6, min(1.0, individual[i]))\n",
    "                elif i == 6:  # colsample_bytree, continuous mutation\n",
    "                    individual[i] += random.gauss(0, 0.1)\n",
    "                    individual[i] = max(0.5, min(1.0, individual[i]))\n",
    "                elif i == 7:  # reg_alpha, continuous mutation\n",
    "                    individual[i] += random.gauss(0, 1.0)\n",
    "                    individual[i] = max(0, min(10.0, individual[i]))\n",
    "                elif i == 8:  # reg_lambda, continuous mutation\n",
    "                    individual[i] += random.gauss(0, 1.0)\n",
    "                    individual[i] = max(0, min(10.0, individual[i]))\n",
    "                elif i == 9:  # pca_n_components, categorical mutation\n",
    "                    individual[i] = random.choice([None, 0.90, 0.99])\n",
    "\n",
    "            print(f\"[lgbm] After mutation: {individual}\")\n",
    "            return individual,\n",
    "\n",
    "        def custom_mate(ind1, ind2):\n",
    "            print(f\"Before crossover:\\n  Parent1: {ind1}\\n  Parent2: {ind2}\")\n",
    "            tools.cxTwoPoint(ind1, ind2)\n",
    "            print(f\"After crossover:\\n  Child1: {ind1}\\n  Child2: {ind2}\")\n",
    "            return ind1, ind2  \n",
    "\n",
    "        # DEAP setup\n",
    "        creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "        creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "        toolbox = base.Toolbox()\n",
    "        \n",
    "        if model_name == 'rf':\n",
    "            toolbox.register(\"n_estimators\", random.randint, 100, 1000)\n",
    "            toolbox.register(\"max_depth\", random.randint, 10, 50)\n",
    "            toolbox.register(\"min_samples_split\", random.randint, 2, 10)\n",
    "            toolbox.register(\"min_samples_leaf\", random.randint, 1, 8)\n",
    "            toolbox.register(\"max_features\", random.choice, [None, 'sqrt', 'log2'])\n",
    "            toolbox.register(\"bootstrap\", random.choice, [True, False])\n",
    "            toolbox.register(\"pca_n_components\", random.choice, [None, 0.90, 0.99])\n",
    "            toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                             (toolbox.n_estimators, toolbox.max_depth, toolbox.min_samples_split,\n",
    "                              toolbox.min_samples_leaf, toolbox.max_features, toolbox.bootstrap,\n",
    "                              toolbox.pca_n_components), n=1)\n",
    "            toolbox.register(\"evaluate\", evaluate_individual_rf)\n",
    "            toolbox.register(\"mutate\", custom_mutate_rf)\n",
    "\n",
    "        elif model_name == 'xgb':\n",
    "            toolbox.register(\"n_estimators\", random.randint, 100, 1000)\n",
    "            toolbox.register(\"max_depth\", random.randint, 10, 50)\n",
    "            toolbox.register(\"learning_rate\", random.uniform, 0.01, 0.3)\n",
    "            toolbox.register(\"subsample\", random.uniform, 0.6, 1.0)\n",
    "            toolbox.register(\"colsample_bytree\", random.uniform, 0.5, 1.0)\n",
    "            toolbox.register(\"gamma\", random.uniform, 0, 1.0)\n",
    "            toolbox.register(\"reg_alpha\", random.uniform, 0, 10.0)\n",
    "            toolbox.register(\"reg_lambda\", random.uniform, 0, 10.0)\n",
    "            toolbox.register(\"pca_n_components\", random.choice, [None, 0.90, 0.99])\n",
    "            toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                             (toolbox.n_estimators, toolbox.max_depth, toolbox.learning_rate, toolbox.subsample,\n",
    "                              toolbox.colsample_bytree, toolbox.gamma, toolbox.reg_alpha, toolbox.reg_lambda,\n",
    "                              toolbox.pca_n_components), n=1)\n",
    "            toolbox.register(\"evaluate\", evaluate_individual_xgb)\n",
    "            toolbox.register(\"mutate\", custom_mutate_xgb)\n",
    "\n",
    "        elif model_name == 'lgbm':\n",
    "            toolbox.register(\"n_estimators\", random.randint, 100, 1000)\n",
    "            toolbox.register(\"max_depth\", random.randint, 10, 50)\n",
    "            toolbox.register(\"learning_rate\", random.uniform, 0.01, 0.3)\n",
    "            toolbox.register(\"num_leaves\", random.randint, 10, 50)\n",
    "            toolbox.register(\"min_child_samples\", random.randint, 5, 100)\n",
    "            toolbox.register(\"subsample\", random.uniform, 0.6, 1.0)\n",
    "            toolbox.register(\"colsample_bytree\", random.uniform, 0.5, 1.0)\n",
    "            toolbox.register(\"reg_alpha\", random.uniform, 0, 10.0)\n",
    "            toolbox.register(\"reg_lambda\", random.uniform, 0, 10.0)\n",
    "            toolbox.register(\"pca_n_components\", random.choice, [None, 0.90, 0.99])\n",
    "            toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                             (toolbox.n_estimators, toolbox.max_depth, toolbox.learning_rate, toolbox.num_leaves,\n",
    "                              toolbox.min_child_samples, toolbox.subsample, toolbox.colsample_bytree,\n",
    "                              toolbox.reg_alpha, toolbox.reg_lambda, toolbox.pca_n_components), n=1)\n",
    "            toolbox.register(\"evaluate\", evaluate_individual_lgbm)\n",
    "            toolbox.register(\"mutate\", custom_mutate_lgbm)\n",
    "\n",
    "        toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "        toolbox.register(\"mate\", custom_mate)\n",
    "        toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "        \n",
    "        population = toolbox.population(n=n_population)\n",
    "        algorithms.eaSimple(population, toolbox, cxpb=cxpb, mutpb=mutpb, ngen=n_generations, verbose=True)\n",
    "        \n",
    "        best_individual = tools.selBest(population, k=1)[0]\n",
    "        \n",
    "        if model_name == 'rf':\n",
    "            best_model = model.set_params(\n",
    "                n_estimators=int(best_individual[0]),\n",
    "                max_depth=int(best_individual[1]),\n",
    "                min_samples_split=int(best_individual[2]),\n",
    "                min_samples_leaf=int(best_individual[3]),\n",
    "                max_features=best_individual[4],\n",
    "                bootstrap=best_individual[5]\n",
    "            )\n",
    "        elif model_name == 'xgb':\n",
    "            best_model = model.set_params(\n",
    "                n_estimators=int(best_individual[0]),\n",
    "                max_depth=int(best_individual[1]),\n",
    "                learning_rate=best_individual[2],\n",
    "                subsample=best_individual[3],\n",
    "                colsample_bytree=best_individual[4],\n",
    "                gamma=best_individual[5],\n",
    "                reg_alpha=best_individual[6],\n",
    "                reg_lambda=best_individual[7]\n",
    "            )\n",
    "        elif model_name == 'lgbm':\n",
    "            best_model = model.set_params(\n",
    "                n_estimators=int(best_individual[0]),\n",
    "                max_depth=int(best_individual[1]),\n",
    "                learning_rate=best_individual[2],\n",
    "                num_leaves=int(best_individual[3]),\n",
    "                min_child_samples=int(best_individual[4]),\n",
    "                subsample=best_individual[5],\n",
    "                colsample_bytree=best_individual[6],\n",
    "                reg_alpha=best_individual[7],\n",
    "                reg_lambda=best_individual[8]\n",
    "            )\n",
    "        \n",
    "        best_estimators[model_name] = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('pca', pca),\n",
    "            ('model', best_model)\n",
    "        ])\n",
    "    \n",
    "    estimators = [(name, model) for name, model in best_estimators.items()]\n",
    "\n",
    "    if problem_type == 'classify':\n",
    "        stacking_model = StackingClassifier(estimators=estimators, final_estimator=RidgeClassifier(), n_jobs=-1)\n",
    "    elif problem_type == 'regress':\n",
    "        stacking_model = StackingRegressor(estimators=estimators, final_estimator=Ridge(), n_jobs=-1)\n",
    "\n",
    "    print(\"\\nEvaluating Stacking Model...\")\n",
    "    cv_results = cross_val_score(stacking_model, X, y, cv=cv, scoring=scoring_metric, verbose=1, n_jobs=-1)\n",
    "    \n",
    "    evaluating_end_time = time.time()\n",
    "    print(f\"\\nModel evaluation took: {evaluating_end_time - evaluating_start_time:.2f} seconds.\\n\")\n",
    "    return stacking_model, cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20c1538",
   "metadata": {
    "papermill": {
     "duration": 0.013607,
     "end_time": "2024-12-30T07:29:11.706008",
     "exception": false,
     "start_time": "2024-12-30T07:29:11.692401",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3153a67e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T22:08:47.699615Z",
     "start_time": "2024-08-26T22:08:47.677159Z"
    },
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-12-30T07:29:11.734479Z",
     "iopub.status.busy": "2024-12-30T07:29:11.734097Z",
     "iopub.status.idle": "2024-12-30T07:29:11.747329Z",
     "shell.execute_reply": "2024-12-30T07:29:11.746028Z"
    },
    "papermill": {
     "duration": 0.030097,
     "end_time": "2024-12-30T07:29:11.749633",
     "exception": false,
     "start_time": "2024-12-30T07:29:11.719536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def manual_undersampling(df, do_under_sample_data=True, target_column=None, desired_samples=1000, seed_value=42, problem_type='classify'):\n",
    "    if not do_under_sample_data:\n",
    "        print(\"Skipping undersampling as 'do_under_sample_data' is set to False.\")\n",
    "        return df\n",
    "\n",
    "    np.random.seed(seed_value)\n",
    "\n",
    "    original_distribution = df[target_column].value_counts()\n",
    "    original_distribution_normalized = df[target_column].value_counts(normalize=True)\n",
    "    sampled_dataframes = []\n",
    "\n",
    "    if problem_type == 'classify':\n",
    "        print(\"Original class distribution (before resampling):\")\n",
    "        original_distribution_df = pd.DataFrame({\n",
    "            target_column: original_distribution.index,\n",
    "            'Raw Counts': original_distribution.values,\n",
    "            'Proportion': original_distribution_normalized.values\n",
    "        })\n",
    "        display(original_distribution_df)\n",
    "        \n",
    "        class_distribution = df[target_column].value_counts(normalize=True)\n",
    "        samples_per_class = (class_distribution * desired_samples).round().astype(int)\n",
    "\n",
    "        total_sampled = samples_per_class.sum()\n",
    "        if total_sampled != desired_samples:\n",
    "            samples_per_class = (class_distribution * (desired_samples / total_sampled * desired_samples)).round().astype(int)\n",
    "        \n",
    "        for cls in df[target_column].unique():\n",
    "            class_df = df[df[target_column] == cls]\n",
    "            class_sample_count = min(len(class_df), samples_per_class[cls])\n",
    "            class_df = class_df.sample(n=class_sample_count, random_state=seed_value)\n",
    "            sampled_dataframes.append(class_df)\n",
    "\n",
    "        df_resampled = pd.concat(sampled_dataframes)\n",
    "        new_distribution = df_resampled[target_column].value_counts()\n",
    "        new_distribution_normalized = df_resampled[target_column].value_counts(normalize=True)\n",
    "        \n",
    "        print(\"\\nNew class distribution (after resampling):\")\n",
    "        new_distribution_df = pd.DataFrame({\n",
    "            target_column: new_distribution.index,\n",
    "            'Raw Counts': new_distribution.values,\n",
    "            'Proportion': new_distribution_normalized.values\n",
    "        })\n",
    "        display(new_distribution_df)\n",
    "\n",
    "        final_sampled = len(df_resampled)\n",
    "        if final_sampled != desired_samples:\n",
    "            print(f\"\\nDesired {desired_samples} samples, but obtained {final_sampled} samples due to class distribution constraints.\")\n",
    "    elif problem_type == 'regress':\n",
    "        if len(df) > desired_samples:\n",
    "            df_resampled = df.sample(n=desired_samples, random_state=seed_value)\n",
    "        else:\n",
    "            df_resampled = df\n",
    "        final_sampled = len(df_resampled)\n",
    "\n",
    "    print(f\"\\nData under-sampled successfully and reduced to {final_sampled} rows.\")\n",
    "    return df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b96e3889",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T22:08:47.699615Z",
     "start_time": "2024-08-26T22:08:47.677159Z"
    },
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-12-30T07:29:11.778378Z",
     "iopub.status.busy": "2024-12-30T07:29:11.777995Z",
     "iopub.status.idle": "2024-12-30T07:29:11.790408Z",
     "shell.execute_reply": "2024-12-30T07:29:11.789157Z"
    },
    "papermill": {
     "duration": 0.029547,
     "end_time": "2024-12-30T07:29:11.792877",
     "exception": false,
     "start_time": "2024-12-30T07:29:11.763330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to get system info\n",
    "def get_system_info():\n",
    "    # Get CPU Name\n",
    "    CPU_Name = None\n",
    "    try:\n",
    "        # Try fetching CPU model on Windows\n",
    "        CPU_Name = platform.processor()\n",
    "        if not CPU_Name:\n",
    "            raise ValueError(\"No CPU name found\")\n",
    "    except Exception:\n",
    "        try:\n",
    "            # Try fetching CPU model on Linux\n",
    "            with open('/proc/cpuinfo') as f:\n",
    "                for line in f:\n",
    "                    if \"model name\" in line:\n",
    "                        CPU_Name = line.split(':')[1].strip()\n",
    "                        break\n",
    "                if not CPU_Name:\n",
    "                    raise ValueError(\"No CPU name found\")\n",
    "        except Exception:\n",
    "            try:\n",
    "                # Try fetching CPU model on macOS\n",
    "                result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], text=True, capture_output=True)\n",
    "                CPU_Name = result.stdout.strip()\n",
    "                if not CPU_Name:\n",
    "                    raise ValueError(\"No CPU name found\")\n",
    "            except Exception:\n",
    "                CPU_Name = \"CPU name could not be determined.\"\n",
    "\n",
    "    # Get GPU Info\n",
    "    GPU_Info = None\n",
    "    try:\n",
    "        if torch.cuda.is_available():\n",
    "            GPU_Info = torch.cuda.get_device_name(0)\n",
    "        else:\n",
    "            GPU_Info = \"No GPU available\"\n",
    "    except Exception:\n",
    "        GPU_Info = \"GPU info could not be determined.\"\n",
    "\n",
    "    # Collect system information\n",
    "    data = {\n",
    "        \"OS Name\": os.name,\n",
    "        \"Python Version\": sys.version.split()[0],\n",
    "        \"Python Executable\": sys.executable,\n",
    "        \"Working Directory\": os.getcwd(),\n",
    "        \"Total RAM (GB)\": f\"{psutil.virtual_memory().total / 1e9:.2f}\",\n",
    "        \"Available RAM (GB)\": f\"{psutil.virtual_memory().available / 1e9:.2f}\",\n",
    "        \"Current Memory Use (GB)\": f\"{psutil.virtual_memory().used / 1e9:.2f}\",\n",
    "        \"CPU Name\": CPU_Name,\n",
    "        \"CPU Freq\": f\"{psutil.cpu_freq().current:.2f}Mhz {psutil.cpu_percent()}%\",\n",
    "        \"Number of Physical CPUs\": psutil.cpu_count(logical=False),\n",
    "        \"CPU Cores\": psutil.cpu_count(),\n",
    "        \"GPU Info\": GPU_Info,\n",
    "        \"Disk Total (GB)\": f\"{psutil.disk_usage('/').total / 1e9:.2f}\",\n",
    "        \"Disk Free (GB)\": f\"{psutil.disk_usage('/').free / 1e9:.2f}\",\n",
    "    }\n",
    "\n",
    "    # Convert dictionary to DataFrame and transpose it\n",
    "    system_info_df = pd.DataFrame(data, index=['VALUE']).T\n",
    "\n",
    "    return system_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d45d07ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T22:08:47.699615Z",
     "start_time": "2024-08-26T22:08:47.677159Z"
    },
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-12-30T07:29:11.821491Z",
     "iopub.status.busy": "2024-12-30T07:29:11.820550Z",
     "iopub.status.idle": "2024-12-30T07:29:11.828952Z",
     "shell.execute_reply": "2024-12-30T07:29:11.827702Z"
    },
    "papermill": {
     "duration": 0.025353,
     "end_time": "2024-12-30T07:29:11.831479",
     "exception": false,
     "start_time": "2024-12-30T07:29:11.806126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def obtain_unique_values_columns(df):\n",
    "    # Sort columns based on the number of unique values, prioritize those with fewer unique values\n",
    "    sorted_columns = sorted(df.columns, key=lambda col: df[col].nunique())\n",
    "\n",
    "    # Collect data for the DataFrame\n",
    "    unique_values_in_columns = []\n",
    "    for col in sorted_columns:\n",
    "        num_unique = df[col].nunique()\n",
    "        unique_values = df[col].unique() if num_unique < 11 else None\n",
    "        unique_values_in_columns.append({\n",
    "            \"Column\": col,\n",
    "            \"Number of Unique Values\": num_unique,\n",
    "            \"Unique Values (for under 11 unique)\": unique_values\n",
    "        })\n",
    "\n",
    "    # Create and return the DataFrame\n",
    "    unique_values_columns_df = pd.DataFrame(unique_values_in_columns)\n",
    "    \n",
    "    return unique_values_columns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6934bd67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T22:08:47.699615Z",
     "start_time": "2024-08-26T22:08:47.677159Z"
    },
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-12-30T07:29:11.859479Z",
     "iopub.status.busy": "2024-12-30T07:29:11.859088Z",
     "iopub.status.idle": "2024-12-30T07:29:11.866921Z",
     "shell.execute_reply": "2024-12-30T07:29:11.865641Z"
    },
    "papermill": {
     "duration": 0.024917,
     "end_time": "2024-12-30T07:29:11.869656",
     "exception": false,
     "start_time": "2024-12-30T07:29:11.844739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to save load and test and confirm the model structure\n",
    "def save_load_test(X, y, model=None, model_file_name=None):\n",
    "    # Save the model to a file\n",
    "    with open(model_file_name, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "    print(f\"Model saved to: {model_file_name}\")\n",
    "\n",
    "    # Load the model from the file\n",
    "    with open(model_file_name, 'rb') as file:\n",
    "        loaded_model = pickle.load(file)\n",
    "    print(\"\\nModel loaded successfully.\")\n",
    "\n",
    "    # Make a prediction on some of the data to ensure it still works\n",
    "    predictions = loaded_model.predict(X.head())\n",
    "\n",
    "    # Show prediction results and actual values\n",
    "    test_results = pd.DataFrame({\n",
    "        'Prediction': predictions,\n",
    "        'Actual': y.head()\n",
    "    })\n",
    "\n",
    "    return loaded_model, test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "578d1599",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T22:08:47.699615Z",
     "start_time": "2024-08-26T22:08:47.677159Z"
    },
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-12-30T07:29:11.898113Z",
     "iopub.status.busy": "2024-12-30T07:29:11.897659Z",
     "iopub.status.idle": "2024-12-30T07:29:11.911121Z",
     "shell.execute_reply": "2024-12-30T07:29:11.909908Z"
    },
    "papermill": {
     "duration": 0.030831,
     "end_time": "2024-12-30T07:29:11.913939",
     "exception": false,
     "start_time": "2024-12-30T07:29:11.883108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_or_generate_data(load_from_file=None, file_name=None, problem_type=None, desired_samples=None, seed_value=None):\n",
    "     \n",
    "    # See if load from file is true\n",
    "    if load_from_file:\n",
    "        try:\n",
    "            # Load the data from the CSV file\n",
    "            df = pd.read_csv(file_name)\n",
    "            print(\"Data loaded successfully.\")\n",
    "        except Exception as e:\n",
    "            # Look for the file in all subdirectories of /kaggle/\n",
    "            file_found = False\n",
    "            try:\n",
    "                for dirname, _, filenames in os.walk('/kaggle/'):\n",
    "                    for filename in filenames:\n",
    "                        if filename == file_name:\n",
    "                            df = pd.read_csv(os.path.join(dirname, filename))\n",
    "                            print(\"Data loaded successfully.\")\n",
    "                            file_found = True\n",
    "                            break\n",
    "                    if file_found:\n",
    "                        break\n",
    "                if not file_found:\n",
    "                    raise FileNotFoundError(f\"File {file_name} not found in local directory or in any /kaggle/ subdirectory.\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "                print(\"Please check the file name and path and try again.\")\n",
    "                return None\n",
    "    else:\n",
    "        # Generate synthetic data based on problem type\n",
    "        if problem_type == 'classify':\n",
    "            X, y = make_classification(n_samples=desired_samples, n_features=20, n_classes=2, n_informative=10, n_clusters_per_class=2, random_state=seed_value)\n",
    "        elif problem_type == 'regress':\n",
    "            X, y = make_regression(n_samples=desired_samples, n_features=20, n_informative=10, noise=0.1, random_state=seed_value)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid 'problem_type' specified. Please set 'problem_type' to either 'classify' or 'regress'.\")\n",
    "\n",
    "        # Create a DataFrame from the generated data\n",
    "        df = pd.DataFrame(X, columns=[f\"Feature_{i+1}\" for i in range(X.shape[1])])\n",
    "        df['target'] = y\n",
    "\n",
    "        print(\"Data generated successfully.\")\n",
    "\n",
    "    # Show the data\n",
    "    print(\"Rows: \", df.shape[0])\n",
    "    print(\"Columns: \", df.shape[1])\n",
    "    print(\"Total Missing values: \", df.isnull().sum().sum())\n",
    "    print(\"Columns with Missing: \", df.columns[df.isnull().any()].tolist())\n",
    "    print(\"\\nFirst 5 rows of the dataframe: \")\n",
    "    display(df.head())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e556f0c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T22:08:47.699615Z",
     "start_time": "2024-08-26T22:08:47.677159Z"
    },
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-12-30T07:29:11.943769Z",
     "iopub.status.busy": "2024-12-30T07:29:11.943342Z",
     "iopub.status.idle": "2024-12-30T07:29:11.950377Z",
     "shell.execute_reply": "2024-12-30T07:29:11.949064Z"
    },
    "papermill": {
     "duration": 0.02486,
     "end_time": "2024-12-30T07:29:11.952951",
     "exception": false,
     "start_time": "2024-12-30T07:29:11.928091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sweetviz_eda(df, report_name=\"Sweetviz_Report.html\", show_eda=True):\n",
    "    if show_eda:\n",
    "        try:\n",
    "            # Create a Sweetviz report\n",
    "            report = sv.analyze(df)\n",
    "\n",
    "            # Save the report to an HTML file\n",
    "            report.show_html(report_name, open_browser=False)\n",
    "\n",
    "            # Display the report in the Jupyter Notebook\n",
    "            display(IFrame(src=report_name, width=1200, height=1200))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"There was an issue generating the Sweetviz report: {e}\")\n",
    "    else:\n",
    "        print(\"Skipping EDA as show_eda is not set to True.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6314d36c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T22:08:47.699615Z",
     "start_time": "2024-08-26T22:08:47.677159Z"
    },
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-12-30T07:29:11.983071Z",
     "iopub.status.busy": "2024-12-30T07:29:11.981808Z",
     "iopub.status.idle": "2024-12-30T07:29:11.987896Z",
     "shell.execute_reply": "2024-12-30T07:29:11.986760Z"
    },
    "papermill": {
     "duration": 0.023504,
     "end_time": "2024-12-30T07:29:11.990579",
     "exception": false,
     "start_time": "2024-12-30T07:29:11.967075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bug_alert_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        print(\"[Alert from function bug_alert_colab()]\\n\\nWARNING:\\n- Hey, we noticed you are in Google Colab.\\n- Please note that as of the time of writing this, LightGBM is not working on Google Colab if GPU is enabled.\\n- Consider setting it to no longer auto-use GPU if it's available, if needed.\\n- If this is no longer applicable feel free to delete this bug alert function.\")\n",
    "    except ImportError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d398b4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T22:08:47.699615Z",
     "start_time": "2024-08-26T22:08:47.677159Z"
    },
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-12-30T07:29:12.019733Z",
     "iopub.status.busy": "2024-12-30T07:29:12.019281Z",
     "iopub.status.idle": "2024-12-30T07:29:12.037637Z",
     "shell.execute_reply": "2024-12-30T07:29:12.036368Z"
    },
    "papermill": {
     "duration": 0.036239,
     "end_time": "2024-12-30T07:29:12.040221",
     "exception": false,
     "start_time": "2024-12-30T07:29:12.003982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_new_or_load_existing_model(df, target_column=None, categorical_threshold=15, model_name='stacking_model', load_existing_model=True, problem_type='classify', n_folds=5, n_population=20, n_generations=10, cxpb=0.5, mutpb=0.2):\n",
    "    \n",
    "    def display_cv_results(cv_results):\n",
    "        print(\"[Stacking Model Genetic Cross-Validation Results]\")\n",
    "        for i, score in enumerate(cv_results):\n",
    "            print(f\"- Fold {i+1} Score: {score:.3f}\")\n",
    "        print(f\"- Average CV Score: {np.mean(cv_results):.3f}\")\n",
    "\n",
    "    def determine_num_and_cat_cols(df, target_column=None, categorical_threshold=15):\n",
    "        # Initialize lists to hold names of categorical and numerical columns\n",
    "        cat_cols = []\n",
    "        num_cols = []\n",
    "\n",
    "        # If no target column is specified, use the last column by default\n",
    "        if target_column is None:\n",
    "            print(\"\\nWARNING: No target column specified, using the last column as default.\\n\")\n",
    "            target_column = df.columns[-1]  # Use the last column as the default target\n",
    "\n",
    "        # Iterate through each column in the DataFrame\n",
    "        print(\"[Auto determining categorical and numerical columns for preprocessors]\\n\")\n",
    "        for col in df.columns:\n",
    "            if col != target_column:  # Skip the target column\n",
    "                # Count the number of unique values in the column\n",
    "                unique_vals = df[col].nunique()\n",
    "\n",
    "                # Determine if the column should be categorical\n",
    "                if unique_vals <= categorical_threshold:\n",
    "                    # If the column is determined to be categorical due to the threshold\n",
    "                    cat_cols.append(col)  # Add to categorical columns list\n",
    "                    print(f\"'{col}' auto added to cat_cols, due to passing categorical_threshold.\")\n",
    "                    # Convert the column to strings then category type\n",
    "                    df[col] = df[col].astype(str).astype('category')\n",
    "                    print(f\"- Converting '{col}' to strings then setting type to category.\\n\")\n",
    "                elif df[col].dtype == 'object' or df[col].dtype.name == 'category':\n",
    "                    # If the column is determined to be categorical due to its type\n",
    "                    cat_cols.append(col)  # Add to categorical columns list\n",
    "                    print(f\"'{col}' auto added to cat_cols, due to being object or categorical type.\")\n",
    "                    # Convert the column to strings then category type\n",
    "                    df[col] = df[col].astype(str).astype('category')\n",
    "                    print(f\"- Converting '{col}' to strings then setting type to category.\\n\")\n",
    "                else:\n",
    "                    # If the column is determined to be numerical\n",
    "                    num_cols.append(col)  # Add to numerical columns list\n",
    "                    print(f\"'{col}' auto added to num_cols, due to not being an object or categorical type.\")\n",
    "                    # Convert the column to a float type\n",
    "                    df[col] = df[col].astype(float)\n",
    "                    print(f\"- Converting '{col}' to floats.\\n\")\n",
    "\n",
    "        # Separate the features (X) from the target (y)\n",
    "        X = df.drop(columns=[target_column])  # Drop the target column to get the feature matrix\n",
    "        y = df[target_column]  # Extract the target column\n",
    "\n",
    "        # Return the features, target, and lists of categorical and numerical columns\n",
    "        return X, y, cat_cols, num_cols\n",
    "\n",
    "    model_filename = f\"{model_name}.pkl\"\n",
    "    stacking_model = None\n",
    "\n",
    "    if load_existing_model:\n",
    "        try:\n",
    "            print(f\"Trying to load the model '{model_filename}' from the file since 'load_existing_model' is set to True.\")\n",
    "            # Load the model from the file\n",
    "            with open(model_filename, 'rb') as file:\n",
    "                stacking_model = pickle.load(file)\n",
    "                print(f\"Model '{model_filename}' loaded successfully.\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File '{model_filename}' not found. Proceeding to create a new model.\")\n",
    "            load_existing_model = False\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred loading the model '{model_filename}': {e}\")\n",
    "            print(\"Please check the file name and path and try again.\")\n",
    "            load_existing_model = False\n",
    "\n",
    "    if not load_existing_model:\n",
    "        print(f\"Creating a new model since 'load_existing_model' is set to False or loading the model failed.\")\n",
    "        print(\"\\nTraining will now begin.\\n\")\n",
    "        # Preprocess Data and Create a New Model\n",
    "        X, y, cat_cols, num_cols = determine_num_and_cat_cols(df, target_column=target_column, categorical_threshold=categorical_threshold)\n",
    "        stacking_model, cv_results = make_pipeline_and_genetic_search(X, y, cat_cols, num_cols,\n",
    "                                                                      problem_type=problem_type,\n",
    "                                                                      n_folds=n_folds,\n",
    "                                                                      n_population=n_population,\n",
    "                                                                      n_generations=n_generations,\n",
    "                                                                      cxpb=cxpb,\n",
    "                                                                      mutpb=mutpb\n",
    "                                                                      )\n",
    "        display_cv_results(cv_results)\n",
    "        # Fit the model on all the data before saving\n",
    "        print(\"\\nEvaluation complete, fitting on all available data.\")\n",
    "        stacking_model.fit(X, y)\n",
    "\n",
    "        # Save the newly created model\n",
    "        with open(model_filename, 'wb') as file:\n",
    "            pickle.dump(stacking_model, file)\n",
    "        print(f\"\\nNew model '{model_filename}' created and saved successfully.\")\n",
    "\n",
    "        # Save the pipeline structure to 'pipeline.html'\n",
    "        with open(\"pipeline.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(estimator_html_repr(stacking_model))\n",
    "        print(\"Pipeline structure has been saved to 'pipeline.html'.\")\n",
    "\n",
    "    return stacking_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9dfe120",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T22:08:47.699615Z",
     "start_time": "2024-08-26T22:08:47.677159Z"
    },
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-12-30T07:29:12.068543Z",
     "iopub.status.busy": "2024-12-30T07:29:12.068131Z",
     "iopub.status.idle": "2024-12-30T07:29:12.080136Z",
     "shell.execute_reply": "2024-12-30T07:29:12.079037Z"
    },
    "papermill": {
     "duration": 0.029833,
     "end_time": "2024-12-30T07:29:12.083253",
     "exception": false,
     "start_time": "2024-12-30T07:29:12.053420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_permutation_importance_plots(df, target_column=None, get_permutation_importance=None, model=None, n_folds=5, seed_value=42, n_repeats=10, colorscale='Viridis'):\n",
    "    if get_permutation_importance is None or not get_permutation_importance:\n",
    "        print(\"Skipping permutation importance as get_permutation_importance is set to False.\")\n",
    "        return None\n",
    "\n",
    "    if target_column is None:\n",
    "        raise ValueError(\"You must specify a target_column.\")\n",
    "\n",
    "    # Separate the features (X) and the target (y)\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    # Function to calculate permutation importance for a single fold\n",
    "    def compute_permutation_importance(fold):\n",
    "        return permutation_importance(model, X, y, n_repeats=n_repeats, random_state=seed_value + fold).importances_mean\n",
    "\n",
    "    # Use joblib to parallelize the permutation importance computation across folds\n",
    "    permutation_importance_folds = Parallel(n_jobs=-1)(delayed(compute_permutation_importance)(fold) for fold in range(n_folds))\n",
    "\n",
    "    # Convert the list to a NumPy array for easier manipulation\n",
    "    permutation_importance_folds = np.array(permutation_importance_folds)\n",
    "\n",
    "    # Create the 3D Plotly figure\n",
    "    x = np.array([np.arange(len(X.columns)) for _ in range(n_folds)])\n",
    "    y = np.array([[fold] * len(X.columns) for fold in range(n_folds)])\n",
    "    z = permutation_importance_folds\n",
    "\n",
    "    fig_3d = go.Figure(data=[go.Surface(z=z, x=x, y=y, colorscale=colorscale)])\n",
    "    fig_3d.update_layout(\n",
    "        title='3D Permutation Importance Across CV Folds',\n",
    "        scene=dict(\n",
    "            xaxis=dict(\n",
    "                ticktext=X.columns,\n",
    "                tickvals=np.arange(len(X.columns)),\n",
    "                title=\"Features\"\n",
    "            ),\n",
    "            yaxis=dict(title=\"CV Fold\"),\n",
    "            zaxis=dict(title=\"Permutation Importance\"),\n",
    "            camera_eye=dict(x=1.5, y=1.5, z=0.6)\n",
    "        ),\n",
    "        width=800,\n",
    "        height=800\n",
    "    )\n",
    "\n",
    "    # Return the 3D figure\n",
    "    return fig_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae954df",
   "metadata": {
    "papermill": {
     "duration": 0.013524,
     "end_time": "2024-12-30T07:29:12.110609",
     "exception": false,
     "start_time": "2024-12-30T07:29:12.097085",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## HELPER CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca64813d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T22:05:41.567912Z",
     "start_time": "2024-08-26T22:05:41.552929Z"
    },
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-12-30T07:29:12.140438Z",
     "iopub.status.busy": "2024-12-30T07:29:12.140050Z",
     "iopub.status.idle": "2024-12-30T07:29:12.162743Z",
     "shell.execute_reply": "2024-12-30T07:29:12.161352Z"
    },
    "papermill": {
     "duration": 0.041247,
     "end_time": "2024-12-30T07:29:12.165696",
     "exception": false,
     "start_time": "2024-12-30T07:29:12.124449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This can be integrated into SKlearn pipeline if desired, or used standalone to fit and transform data.\n",
    "class CustomSupConFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    class SupConLoss(nn.Module):\n",
    "        def __init__(self, temperature=0.07):\n",
    "            super(CustomSupConFeatureExtractor.SupConLoss, self).__init__()\n",
    "            self.temperature = temperature\n",
    "\n",
    "        def forward(self, features, labels):\n",
    "            features = nn.functional.normalize(features, dim=1)\n",
    "            similarity_matrix = torch.matmul(features, features.T) / self.temperature\n",
    "            labels = labels.unsqueeze(1)\n",
    "            mask = torch.eq(labels, labels.T).float()\n",
    "            log_softmax_sim = nn.functional.log_softmax(similarity_matrix, dim=1)\n",
    "            loss = -torch.sum(mask * log_softmax_sim) / torch.sum(mask)\n",
    "            return loss\n",
    "\n",
    "    class SimpleNN(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim):\n",
    "            super(CustomSupConFeatureExtractor.SimpleNN, self).__init__()\n",
    "            self.fc1 = nn.Linear(input_dim, 128)\n",
    "            self.fc2 = nn.Linear(128, 64)\n",
    "            self.fc3 = nn.Linear(64, output_dim)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = torch.relu(self.fc1(x))\n",
    "            x = torch.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "    def __init__(self, input_dim, output_dim=None, temperature=0.07, epochs=1, batch_size=32, learning_rate=0.01, early_stopping=False, patience=5):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim  # Keep the original value of output_dim\n",
    "        self.temperature = temperature\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.early_stopping = early_stopping\n",
    "        self.patience = patience\n",
    "        self.model = None  # Initialize model as None\n",
    "        self.criterion = None\n",
    "        self.optimizer = None\n",
    "\n",
    "        if self.input_dim is not None and self.output_dim is not None:\n",
    "            if isinstance(self.output_dim, float) and self.output_dim < 1:\n",
    "                effective_output_dim = max(1, int(np.ceil(self.input_dim * self.output_dim)))\n",
    "            else:\n",
    "                effective_output_dim = self.output_dim\n",
    "\n",
    "            self.model = self.SimpleNN(input_dim, effective_output_dim)\n",
    "            self.criterion = self.SupConLoss(temperature=temperature)\n",
    "            self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if self.model is None:\n",
    "            return self  # Skip fitting if model is None\n",
    "\n",
    "        # Automatically convert DataFrame to numpy array if necessary\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "\n",
    "        train_dataset = torch.utils.data.TensorDataset(torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.long))\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        best_loss = np.inf\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            self.model.train()\n",
    "            epoch_loss = 0\n",
    "\n",
    "            for inputs, labels in train_loader:\n",
    "                self.optimizer.zero_grad()\n",
    "                features = self.model(inputs)\n",
    "                loss = self.criterion(features, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "            epoch_loss /= len(train_loader)\n",
    "\n",
    "            if self.early_stopping:\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    epochs_no_improve = 0\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "\n",
    "                if epochs_no_improve >= self.patience:\n",
    "                    print(f\"[CustomSupConFeatureExtractor] Early stopping triggered after {epoch+1} epochs.\")\n",
    "                    break\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.model is None:\n",
    "            return X  # Return the original features if model is None\n",
    "\n",
    "        # Automatically convert DataFrame to numpy array if necessary\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "            return self.model(X_tensor).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e31ebdd",
   "metadata": {
    "papermill": {
     "duration": 0.013389,
     "end_time": "2024-12-30T07:29:12.192345",
     "exception": false,
     "start_time": "2024-12-30T07:29:12.178956",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SET IMPORTANT VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6b8c262",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T22:05:41.584143Z",
     "start_time": "2024-08-26T22:05:41.568911Z"
    },
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-12-30T07:29:12.221542Z",
     "iopub.status.busy": "2024-12-30T07:29:12.221135Z",
     "iopub.status.idle": "2024-12-30T07:29:12.234479Z",
     "shell.execute_reply": "2024-12-30T07:29:12.233237Z"
    },
    "papermill": {
     "duration": 0.031282,
     "end_time": "2024-12-30T07:29:12.237160",
     "exception": false,
     "start_time": "2024-12-30T07:29:12.205878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basics\n",
    "\n",
    "seed_value = 42                      # For reproducibility\n",
    "problem_type = 'classify'            # 'classify' or 'regress' depending on your task.\n",
    "target_column = 'Pop'                # The target column in your dataset.\n",
    "load_from_file = True                # Load data from a CSV file or generate sample data.\n",
    "file_name = 'possum.csv'             # Provide the name of the CSV file if loading data from a file.\n",
    "desired_samples = 4000               # Controls the total number of samples to generate if not loading from a file.\n",
    "                                     # Determines the number of samples retained after undersampling if applicable.\n",
    "do_under_sample_data = True          # Controls if you want to undersample your data to balance class distribution or reduce dataset size.\n",
    "                                     # The desired_samples parameter will control the number of samples retained.\n",
    "show_eda = True                      # Decide whether to display EDA (Exploratory Data Analysis).\n",
    "\n",
    "# Genetic Algorithm and Model Loading Settings\n",
    "\n",
    "load_existing_model = False          # Load an existing model from the current directory.\n",
    "                                     # The code saves the model after making by default, so will use the same model unless you delete it.\n",
    "model_name = 'possum_model'          # The name to save the new model as, or the name to try loading the existing model as.\n",
    "n_folds = 5                          # Set the number of folds for cross-validation. This setting applies to everything that uses cross-validation in the notebook.\n",
    "                                     # This also applies to both the cross-validation during permutation feature importance\n",
    "categorical_threshold = 15           # Adjust the threshold for treating a column as categorical.\n",
    "n_population = 9                     # Adjust the population size for the genetic algorithm.\n",
    "n_generations = 4                    # Set the number of generations for the genetic algorithm.\n",
    "cxpb = 0.5                           # Modify the crossover probability for the genetic algorithm.\n",
    "mutpb = 0.2                          # Adjust the mutation probability for the genetic algorithm.\n",
    "\n",
    "# Permutation Feature Importance Settings\n",
    "\n",
    "get_permutation_importance = True    # Decide whether to show permutation importance.\n",
    "n_repeats = 10                       # Set the number of times to repeat the permutation importance calculation.\n",
    "                                     # This will be validated by the same number of folds in n_folds.\n",
    "\n",
    "# Hide warnings\n",
    "warnings.simplefilter(\"ignore\")  \n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "torch.manual_seed(seed_value)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)  # if using multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dca449",
   "metadata": {
    "papermill": {
     "duration": 0.014052,
     "end_time": "2024-12-30T07:29:12.265056",
     "exception": false,
     "start_time": "2024-12-30T07:29:12.251004",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# KNOWN BUG ALERTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ee478ce",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-12-30T07:29:12.293498Z",
     "iopub.status.busy": "2024-12-30T07:29:12.293105Z",
     "iopub.status.idle": "2024-12-30T07:29:12.300258Z",
     "shell.execute_reply": "2024-12-30T07:29:12.299125Z"
    },
    "papermill": {
     "duration": 0.024873,
     "end_time": "2024-12-30T07:29:12.303125",
     "exception": false,
     "start_time": "2024-12-30T07:29:12.278252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If the user is in colab, give them any warnings related to colab\n",
    "bug_alert_colab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05566b3",
   "metadata": {
    "papermill": {
     "duration": 0.013452,
     "end_time": "2024-12-30T07:29:12.330101",
     "exception": false,
     "start_time": "2024-12-30T07:29:12.316649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SYSTEM INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c608aa29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T22:05:41.615916Z",
     "start_time": "2024-08-26T22:05:41.585039Z"
    },
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-12-30T07:29:12.359198Z",
     "iopub.status.busy": "2024-12-30T07:29:12.358769Z",
     "iopub.status.idle": "2024-12-30T07:29:12.387180Z",
     "shell.execute_reply": "2024-12-30T07:29:12.385627Z"
    },
    "papermill": {
     "duration": 0.04663,
     "end_time": "2024-12-30T07:29:12.390411",
     "exception": false,
     "start_time": "2024-12-30T07:29:12.343781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OS Name</th>\n",
       "      <td>posix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python Version</th>\n",
       "      <td>3.7.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python Executable</th>\n",
       "      <td>/opt/conda/bin/python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Working Directory</th>\n",
       "      <td>/kaggle/working</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total RAM (GB)</th>\n",
       "      <td>33.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Available RAM (GB)</th>\n",
       "      <td>32.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Current Memory Use (GB)</th>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CPU Name</th>\n",
       "      <td>x86_64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CPU Freq</th>\n",
       "      <td>2200.26Mhz 21.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Physical CPUs</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CPU Cores</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPU Info</th>\n",
       "      <td>No GPU available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disk Total (GB)</th>\n",
       "      <td>8656.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disk Free (GB)</th>\n",
       "      <td>2174.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         VALUE\n",
       "OS Name                                  posix\n",
       "Python Version                          3.7.12\n",
       "Python Executable        /opt/conda/bin/python\n",
       "Working Directory              /kaggle/working\n",
       "Total RAM (GB)                           33.66\n",
       "Available RAM (GB)                       32.42\n",
       "Current Memory Use (GB)                   0.76\n",
       "CPU Name                                x86_64\n",
       "CPU Freq                      2200.26Mhz 21.5%\n",
       "Number of Physical CPUs                      2\n",
       "CPU Cores                                    4\n",
       "GPU Info                      No GPU available\n",
       "Disk Total (GB)                        8656.92\n",
       "Disk Free (GB)                         2174.08"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get system information\n",
    "system_info_df = get_system_info()\n",
    "\n",
    "# Display system information\n",
    "system_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddbed9f",
   "metadata": {
    "id": "988cebb2",
    "papermill": {
     "duration": 0.013145,
     "end_time": "2024-12-30T07:29:12.417224",
     "exception": false,
     "start_time": "2024-12-30T07:29:12.404079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD OR GENERATE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab0f13f",
   "metadata": {
    "papermill": {
     "duration": 0.013008,
     "end_time": "2024-12-30T07:29:12.443703",
     "exception": false,
     "start_time": "2024-12-30T07:29:12.430695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"border:3px solid #9370DB; padding: 15px; border-radius: 15px; background-color: #F3E5F5;\">\n",
    "    <h3 style=\"color: #6A5ACD; text-align: center;\">Reminder: Adjust Data Loading and Sampling Settings</h3>\n",
    "    <p style=\"font-size: 15px; color: #333333; text-align: center;\">\n",
    "        Before proceeding, please make sure to review and adjust the following settings in the <strong>SET IMPORTANT VARIABLES</strong> section of this notebook as needed:\n",
    "    </p>\n",
    "    <ul style=\"font-size: 14px; color: #333333;\">\n",
    "        <li><strong>load_from_file</strong>: Load data from a CSV file or generate sample data.</li>\n",
    "        <li><strong>file_name</strong>: Provide the name of the CSV file if loading data from a file.</li>\n",
    "        <li><strong>problem_type</strong>: 'classify' or 'regress' depending on your task.</li>\n",
    "        <li><strong>desired_samples</strong>: \n",
    "            <ul>\n",
    "                <li>Controls the total number of samples to generate if not loading from a file.</li>\n",
    "                <li>Determines the number of samples retained after undersampling if applicable.</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><strong>seed_value</strong>: For reproducibility.</li>\n",
    "    </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00a4418d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T22:05:41.678997Z",
     "start_time": "2024-08-26T22:05:41.616916Z"
    },
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-12-30T07:29:12.473144Z",
     "iopub.status.busy": "2024-12-30T07:29:12.472700Z",
     "iopub.status.idle": "2024-12-30T07:29:12.513989Z",
     "shell.execute_reply": "2024-12-30T07:29:12.512804Z"
    },
    "papermill": {
     "duration": 0.058736,
     "end_time": "2024-12-30T07:29:12.516756",
     "exception": false,
     "start_time": "2024-12-30T07:29:12.458020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "Rows:  104\n",
      "Columns:  14\n",
      "Total Missing values:  3\n",
      "Columns with Missing:  ['age', 'footlgth']\n",
      "\n",
      "First 5 rows of the dataframe: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>site</th>\n",
       "      <th>Pop</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>hdlngth</th>\n",
       "      <th>skullw</th>\n",
       "      <th>totlngth</th>\n",
       "      <th>taill</th>\n",
       "      <th>footlgth</th>\n",
       "      <th>earconch</th>\n",
       "      <th>eye</th>\n",
       "      <th>chest</th>\n",
       "      <th>belly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>m</td>\n",
       "      <td>8.0</td>\n",
       "      <td>94.1</td>\n",
       "      <td>60.4</td>\n",
       "      <td>89.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>74.5</td>\n",
       "      <td>54.5</td>\n",
       "      <td>15.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>6.0</td>\n",
       "      <td>92.5</td>\n",
       "      <td>57.6</td>\n",
       "      <td>91.5</td>\n",
       "      <td>36.5</td>\n",
       "      <td>72.5</td>\n",
       "      <td>51.2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>6.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>95.5</td>\n",
       "      <td>39.0</td>\n",
       "      <td>75.4</td>\n",
       "      <td>51.9</td>\n",
       "      <td>15.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>6.0</td>\n",
       "      <td>93.2</td>\n",
       "      <td>57.1</td>\n",
       "      <td>92.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>76.1</td>\n",
       "      <td>52.2</td>\n",
       "      <td>15.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>2.0</td>\n",
       "      <td>91.5</td>\n",
       "      <td>56.3</td>\n",
       "      <td>85.5</td>\n",
       "      <td>36.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>53.2</td>\n",
       "      <td>15.1</td>\n",
       "      <td>28.5</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   case  site  Pop sex  age  hdlngth  skullw  totlngth  taill  footlgth  \\\n",
       "0     1     1  Vic   m  8.0     94.1    60.4      89.0   36.0      74.5   \n",
       "1     2     1  Vic   f  6.0     92.5    57.6      91.5   36.5      72.5   \n",
       "2     3     1  Vic   f  6.0     94.0    60.0      95.5   39.0      75.4   \n",
       "3     4     1  Vic   f  6.0     93.2    57.1      92.0   38.0      76.1   \n",
       "4     5     1  Vic   f  2.0     91.5    56.3      85.5   36.0      71.0   \n",
       "\n",
       "   earconch   eye  chest  belly  \n",
       "0      54.5  15.2   28.0   36.0  \n",
       "1      51.2  16.0   28.5   33.0  \n",
       "2      51.9  15.5   30.0   34.0  \n",
       "3      52.2  15.2   28.0   34.0  \n",
       "4      53.2  15.1   28.5   33.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = load_or_generate_data(load_from_file=load_from_file, \n",
    "                           file_name=file_name, \n",
    "                           problem_type=problem_type,\n",
    "                           desired_samples=desired_samples,\n",
    "                           seed_value=seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53859a0",
   "metadata": {
    "papermill": {
     "duration": 0.013472,
     "end_time": "2024-12-30T07:29:12.544126",
     "exception": false,
     "start_time": "2024-12-30T07:29:12.530654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DTYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52fa61cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T22:05:41.726238Z",
     "start_time": "2024-08-26T22:05:41.713330Z"
    },
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-12-30T07:29:12.574492Z",
     "iopub.status.busy": "2024-12-30T07:29:12.574118Z",
     "iopub.status.idle": "2024-12-30T07:29:12.583611Z",
     "shell.execute_reply": "2024-12-30T07:29:12.582140Z"
    },
    "papermill": {
     "duration": 0.028455,
     "end_time": "2024-12-30T07:29:12.586306",
     "exception": false,
     "start_time": "2024-12-30T07:29:12.557851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case          int64\n",
       "site          int64\n",
       "Pop          object\n",
       "sex          object\n",
       "age         float64\n",
       "hdlngth     float64\n",
       "skullw      float64\n",
       "totlngth    float64\n",
       "taill       float64\n",
       "footlgth    float64\n",
       "earconch    float64\n",
       "eye         float64\n",
       "chest       float64\n",
       "belly       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the data types of each column\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebacd4bc",
   "metadata": {
    "papermill": {
     "duration": 0.013797,
     "end_time": "2024-12-30T07:29:12.614956",
     "exception": false,
     "start_time": "2024-12-30T07:29:12.601159",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# UNIQUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0c73358",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T22:05:41.772813Z",
     "start_time": "2024-08-26T22:05:41.728238Z"
    },
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-12-30T07:29:12.645535Z",
     "iopub.status.busy": "2024-12-30T07:29:12.645167Z",
     "iopub.status.idle": "2024-12-30T07:29:12.668808Z",
     "shell.execute_reply": "2024-12-30T07:29:12.667613Z"
    },
    "papermill": {
     "duration": 0.042063,
     "end_time": "2024-12-30T07:29:12.671396",
     "exception": false,
     "start_time": "2024-12-30T07:29:12.629333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Number of Unique Values</th>\n",
       "      <th>Unique Values (for under 11 unique)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pop</td>\n",
       "      <td>2</td>\n",
       "      <td>[Vic, other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sex</td>\n",
       "      <td>2</td>\n",
       "      <td>[m, f]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>site</td>\n",
       "      <td>7</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>age</td>\n",
       "      <td>9</td>\n",
       "      <td>[8.0, 6.0, 2.0, 1.0, 9.0, 5.0, 3.0, 4.0, 7.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>taill</td>\n",
       "      <td>19</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chest</td>\n",
       "      <td>19</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>belly</td>\n",
       "      <td>24</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>totlngth</td>\n",
       "      <td>34</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>eye</td>\n",
       "      <td>35</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>skullw</td>\n",
       "      <td>64</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>earconch</td>\n",
       "      <td>69</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hdlngth</td>\n",
       "      <td>71</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>footlgth</td>\n",
       "      <td>75</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>case</td>\n",
       "      <td>104</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Column  Number of Unique Values  \\\n",
       "0        Pop                        2   \n",
       "1        sex                        2   \n",
       "2       site                        7   \n",
       "3        age                        9   \n",
       "4      taill                       19   \n",
       "5      chest                       19   \n",
       "6      belly                       24   \n",
       "7   totlngth                       34   \n",
       "8        eye                       35   \n",
       "9     skullw                       64   \n",
       "10  earconch                       69   \n",
       "11   hdlngth                       71   \n",
       "12  footlgth                       75   \n",
       "13      case                      104   \n",
       "\n",
       "                  Unique Values (for under 11 unique)  \n",
       "0                                        [Vic, other]  \n",
       "1                                              [m, f]  \n",
       "2                               [1, 2, 3, 4, 5, 6, 7]  \n",
       "3   [8.0, 6.0, 2.0, 1.0, 9.0, 5.0, 3.0, 4.0, 7.0, ...  \n",
       "4                                                None  \n",
       "5                                                None  \n",
       "6                                                None  \n",
       "7                                                None  \n",
       "8                                                None  \n",
       "9                                                None  \n",
       "10                                               None  \n",
       "11                                               None  \n",
       "12                                               None  \n",
       "13                                               None  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values_columns_df = obtain_unique_values_columns(df)\n",
    "\n",
    "unique_values_columns_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0290ba7",
   "metadata": {
    "papermill": {
     "duration": 0.013845,
     "end_time": "2024-12-30T07:29:12.699316",
     "exception": false,
     "start_time": "2024-12-30T07:29:12.685471",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# OPTIONALLY UNDERSAMPLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8c8157",
   "metadata": {
    "papermill": {
     "duration": 0.013788,
     "end_time": "2024-12-30T07:29:12.728066",
     "exception": false,
     "start_time": "2024-12-30T07:29:12.714278",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"border:3px solid #FFD700; padding: 15px; border-radius: 15px; background-color: #FFFACD;\">\n",
    "    <h3 style=\"color: #DAA520; text-align: center;\">Reminder: Adjust Sampling and Undersampling Settings</h3>\n",
    "    <p style=\"font-size: 15px; color: #333333; text-align: center;\">\n",
    "        Before proceeding, please make sure to review and adjust the following settings in the <strong>SET IMPORTANT VARIABLES</strong> section of this notebook as needed:\n",
    "    </p>\n",
    "    <ul style=\"font-size: 14px; color: #333333;\">\n",
    "        <li><strong>do_undersample_data</strong>: Controls whether to undersample your data (maintaining class balance in classification tasks) regardless of whether the data was loaded or generated. The <strong>desired_samples</strong> parameter controls the number of samples retained after undersampling.</li>\n",
    "        <li><strong>target_column</strong>: The target column in your dataset.</li>\n",
    "        <li><strong>desired_samples</strong>: \n",
    "            <ul>\n",
    "                <li>Controls the total number of samples to generate if not loading from a file.</li>\n",
    "                <li>Determines the number of samples retained after undersampling, if applicable.</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><strong>seed_value</strong>: For reproducibility.</li>\n",
    "        <li><strong>problem_type</strong>: 'classify' or 'regress' depending on your task.</li>\n",
    "    </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3224a18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T22:05:41.788772Z",
     "start_time": "2024-08-26T22:05:41.774322Z"
    },
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-12-30T07:29:12.757807Z",
     "iopub.status.busy": "2024-12-30T07:29:12.757376Z",
     "iopub.status.idle": "2024-12-30T07:29:12.790617Z",
     "shell.execute_reply": "2024-12-30T07:29:12.789443Z"
    },
    "papermill": {
     "duration": 0.052923,
     "end_time": "2024-12-30T07:29:12.795035",
     "exception": false,
     "start_time": "2024-12-30T07:29:12.742112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution (before resampling):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pop</th>\n",
       "      <th>Raw Counts</th>\n",
       "      <th>Proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>other</td>\n",
       "      <td>58</td>\n",
       "      <td>0.557692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vic</td>\n",
       "      <td>46</td>\n",
       "      <td>0.442308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pop  Raw Counts  Proportion\n",
       "0  other          58    0.557692\n",
       "1    Vic          46    0.442308"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New class distribution (after resampling):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pop</th>\n",
       "      <th>Raw Counts</th>\n",
       "      <th>Proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>other</td>\n",
       "      <td>58</td>\n",
       "      <td>0.557692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vic</td>\n",
       "      <td>46</td>\n",
       "      <td>0.442308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pop  Raw Counts  Proportion\n",
       "0  other          58    0.557692\n",
       "1    Vic          46    0.442308"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Desired 4000 samples, but obtained 104 samples due to class distribution constraints.\n",
      "\n",
      "Data under-sampled successfully and reduced to 104 rows.\n"
     ]
    }
   ],
   "source": [
    "# Optionally under-sample the data\n",
    "df = manual_undersampling(df, \n",
    "                          do_under_sample_data=do_under_sample_data, \n",
    "                          target_column=target_column, \n",
    "                          desired_samples=desired_samples, \n",
    "                          seed_value=seed_value, \n",
    "                          problem_type=problem_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2c04ca",
   "metadata": {
    "papermill": {
     "duration": 0.014256,
     "end_time": "2024-12-30T07:29:12.823677",
     "exception": false,
     "start_time": "2024-12-30T07:29:12.809421",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MANUAL ADJUSTMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97833f31",
   "metadata": {
    "papermill": {
     "duration": 0.01405,
     "end_time": "2024-12-30T07:29:12.852222",
     "exception": false,
     "start_time": "2024-12-30T07:29:12.838172",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"border:2px solid #FF6347; padding: 10px; border-radius: 10px; background-color: #FFE4E1;\">\n",
    "    <h3 style=\"color: #FF4500; text-align: center;\">Reminder: Perform Manual Adjustments</h3>\n",
    "    <p style=\"font-size: 14px; color: #333333; text-align: center;\">\n",
    "        This section is intended for any manual adjustments you may need to make to your target or features. Ensure that you review and apply any necessary changes here.\n",
    "    </p>\n",
    "    <ul style=\"font-size: 14px; color: #333333;\">\n",
    "        <li><strong>Target Adjustments</strong>: Check if any conversions or adjustments are required for your target variable.</li>\n",
    "        <li><strong>Feature Adjustments</strong>: Review your features to see if any manual modifications are needed.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fb23e10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T22:05:41.804098Z",
     "start_time": "2024-08-26T22:05:41.790423Z"
    },
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-12-30T07:29:12.882684Z",
     "iopub.status.busy": "2024-12-30T07:29:12.882305Z",
     "iopub.status.idle": "2024-12-30T07:29:12.892700Z",
     "shell.execute_reply": "2024-12-30T07:29:12.891310Z"
    },
    "papermill": {
     "duration": 0.02875,
     "end_time": "2024-12-30T07:29:12.895371",
     "exception": false,
     "start_time": "2024-12-30T07:29:12.866621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target manually adjusted as per the following steps:\n",
      " - Converted target values from Vic and other to 1 and 0\n",
      "\n",
      "Features manually adjusted as per the following steps:\n",
      " - No conversions needed\n"
     ]
    }
   ],
   "source": [
    "# Tell user target adjustments being made\n",
    "print(\"Target manually adjusted as per the following steps:\")\n",
    "\n",
    "# Convert values in the \"Pop\" column from \"Vic\" to 1 and \"Other\" to 0\n",
    "df.loc[df[\"Pop\"] == \"Vic\", \"target\"] = \"1\"\n",
    "df.loc[df[\"Pop\"] == \"other\", \"target\"] = \"0\"\n",
    "print(\" - Converted target values from Vic and other to 1 and 0\")\n",
    "\n",
    "print(\"\\nFeatures manually adjusted as per the following steps:\")\n",
    "\n",
    "print(\" - No conversions needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ffdfec",
   "metadata": {
    "papermill": {
     "duration": 0.014383,
     "end_time": "2024-12-30T07:29:12.924274",
     "exception": false,
     "start_time": "2024-12-30T07:29:12.909891",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a273d5",
   "metadata": {
    "papermill": {
     "duration": 0.014427,
     "end_time": "2024-12-30T07:29:12.953332",
     "exception": false,
     "start_time": "2024-12-30T07:29:12.938905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"border:3px solid #32CD32; padding: 15px; border-radius: 15px; background-color: #F0FFF0;\">\n",
    "    <h3 style=\"color: #228B22; text-align: center;\">Reminder: Adjust EDA Display Setting</h3>\n",
    "    <p style=\"font-size: 15px; color: #333333; text-align: center;\">\n",
    "        Before proceeding, please make sure to review and adjust the following settings in the <strong>SET IMPORTANT VARIABLES</strong> section of this notebook as needed:\n",
    "    </p>\n",
    "    <ul style=\"font-size: 14px; color: #333333;\">\n",
    "        <li><strong>show_eda</strong>: Decide whether to display EDA (Exploratory Data Analysis) based on whether you need a quick overview of the data or wish to skip it for rapid testing.</li>\n",
    "    </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a15032d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T22:05:49.285459Z",
     "start_time": "2024-08-26T22:05:41.805105Z"
    },
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-12-30T07:29:12.984391Z",
     "iopub.status.busy": "2024-12-30T07:29:12.983973Z",
     "iopub.status.idle": "2024-12-30T07:29:22.389086Z",
     "shell.execute_reply": "2024-12-30T07:29:22.387876Z"
    },
    "papermill": {
     "duration": 9.424413,
     "end_time": "2024-12-30T07:29:22.392400",
     "exception": false,
     "start_time": "2024-12-30T07:29:12.967987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b206e1009e07477e8b9729825118bc35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |          | [  0%]   00:00 -> (? left)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report Sweetviz_Report.html was generated.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"1200\"\n",
       "            src=\"Sweetviz_Report.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ace2f304450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sweetviz_eda(df, \n",
    "             show_eda=show_eda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60d2d50",
   "metadata": {
    "papermill": {
     "duration": 0.018629,
     "end_time": "2024-12-30T07:29:22.426314",
     "exception": false,
     "start_time": "2024-12-30T07:29:22.407685",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GENETIC CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a016b579",
   "metadata": {
    "papermill": {
     "duration": 0.015713,
     "end_time": "2024-12-30T07:29:22.461356",
     "exception": false,
     "start_time": "2024-12-30T07:29:22.445643",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"border:2px solid #87CEFA; padding: 20px; border-radius: 10px; background-color: #F0F8FF; color: #333333; font-family: Arial, sans-serif;\">\n",
    "    <h3 style=\"color: #4682B4; text-align: center;\">Reminder: Adjust Genetic Search and Model Loading Settings</h3>\n",
    "    <p style=\"font-size: 14px; color: #333333; text-align: center;\">\n",
    "        Before proceeding, please make sure to review and adjust the following settings in the <strong>SET IMPORTANT VARIABLES</strong> section of this notebook as needed:\n",
    "    </p>\n",
    "    <ul style=\"font-size: 14px; color: #333333; margin-top: 10px;\">\n",
    "        <li><strong>target_column</strong>: The target column in your dataset.</li>\n",
    "        <li><strong>categorical_threshold</strong>: Adjust the threshold for treating a column as categorical.</li>\n",
    "        <li><strong>model_name</strong>: The name to save the new model as, or the name to try loading the existing model as.</li>\n",
    "        <li><strong>load_existing_model</strong>: Decide whether to load an existing model from the current directory. Remember, the code saves the model at the end, so by default, it will use the same model unless you delete it.</li>\n",
    "        <li><strong>problem_type</strong>: 'classify' or 'regress' depending on your task.</li>\n",
    "        <li><strong>n_folds</strong>: Set the number of folds for cross-validation. This setting applies to everything that uses cross-validation in the notebook.</li>\n",
    "        <li><strong>n_population</strong>: Adjust the number of individuals in the population based on your problem size and available resources.</li>\n",
    "        <li><strong>n_generations</strong>: Modify the number of generations to ensure adequate exploration of the search space.</li>\n",
    "        <li><strong>cxpb</strong>: Review the crossover probability to balance exploration and exploitation.</li>\n",
    "        <li><strong>mutpb</strong>: Adjust the mutation probability to control the diversity in the population.</li>\n",
    "    </ul>\n",
    "    <p style=\"font-size: 14px; color: #333333; margin-top: 15px;\">\n",
    "        <strong>Technical Example:</strong><br>\n",
    "        Let's follow the journey of three models: Model1 (RandomForest), Model2 (XGBoost), and Model3 (LightGBM) through the genetic algorithm.\n",
    "    </p>\n",
    "    <ol style=\"font-size: 14px; color: #333333; margin-top: 10px;\">\n",
    "        <li><strong>Initial Population Generation:</strong><br>\n",
    "        The genetic algorithm starts by generating an initial population of lets say 20 individuals for each model. Each individual is a unique configuration of hyperparameters. For example, an individual for Model1 might have 500 trees (<code>n_estimators</code>), a maximum depth of 15 (<code>max_depth</code>), and a 70% sampling rate (<code>subsample</code>).</li>\n",
    "        <li><strong>Evaluation:</strong><br>\n",
    "        Each individual's fitness is evaluated using cross-validation on the dataset. For instance, an individual for Model1 might achieve an accuracy of 0.85. This fitness score determines how well the individual performs.</li>\n",
    "        <li><strong>Tournament Selection:</strong><br>\n",
    "        The algorithm conducts tournaments to select parents for the next generation. In each tournament, a small group of individuals is randomly selected from the population. The individual with the highest fitness in this group wins the tournament and is selected as a parent. For example, if Model3's tournament includes individuals with accuracies of 0.82, 0.84, and 0.88, the individual with 0.88 would be selected.</li>\n",
    "        <li><strong>Crossover (Mating):</strong><br>\n",
    "        Once parents are selected, they undergo crossover to produce offspring. For example, if a Model1 individual with 500 trees and a maximum depth of 15 mates with another individual with 400 trees and a depth of 20, their offspring might inherit 500 trees from one parent and a depth of 20 from the other.</li>\n",
    "        <li><strong>Mutation:</strong><br>\n",
    "        After crossover, some offspring undergo mutation. This might involve randomly increasing the <code>learning_rate</code> of a Model2 individual from 0.1 to 0.12. Mutation ensures that the algorithm continues to explore new regions of the hyperparameter space.</li>\n",
    "        <li><strong>New Generation:</strong><br>\n",
    "        The offspring replace the old population, and the process of evaluation, selection, crossover, and mutation is repeated. Over multiple generations, the population evolves, with better-performing individuals gradually becoming more common.</li>\n",
    "        <li><strong>Final Model Selection:</strong><br>\n",
    "        After 10 generations, the best individual for each model is selected. For example, Model1 might have evolved to use 700 trees with a maximum depth of 18, achieving an accuracy of 0.90. These best individuals are the final optimized models.</li>\n",
    "        <li><strong>Stacking:</strong><br>\n",
    "        The optimized models (Model1, Model2, and Model3) are then combined in a stacking ensemble. In stacking, the predictions from each model are used as inputs to a final estimator (e.g., RidgeClassifier). This final model learns how to best combine the strengths of Model1, Model2, and Model3 to improve overall prediction performance.</li>\n",
    "        <li><strong>Final Evaluation:</strong><br>\n",
    "        The stacked model is evaluated using cross-validation to ensure that it generalizes well to unseen data. The final result is a robust, optimized model that benefits from the combined power of multiple machine learning algorithms.</li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17cc2e85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T22:06:15.360586Z",
     "start_time": "2024-08-26T22:05:49.302129Z"
    },
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-12-30T07:29:22.500322Z",
     "iopub.status.busy": "2024-12-30T07:29:22.499898Z",
     "iopub.status.idle": "2024-12-30T07:33:13.321959Z",
     "shell.execute_reply": "2024-12-30T07:33:13.320532Z"
    },
    "papermill": {
     "duration": 230.844649,
     "end_time": "2024-12-30T07:33:13.324534",
     "exception": false,
     "start_time": "2024-12-30T07:29:22.479885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new model since 'load_existing_model' is set to False or loading the model failed.\n",
      "\n",
      "Training will now begin.\n",
      "\n",
      "[Auto determining categorical and numerical columns for preprocessors]\n",
      "\n",
      "'case' auto added to num_cols, due to not being an object or categorical type.\n",
      "- Converting 'case' to floats.\n",
      "\n",
      "'site' auto added to cat_cols, due to passing categorical_threshold.\n",
      "- Converting 'site' to strings then setting type to category.\n",
      "\n",
      "'sex' auto added to cat_cols, due to passing categorical_threshold.\n",
      "- Converting 'sex' to strings then setting type to category.\n",
      "\n",
      "'age' auto added to cat_cols, due to passing categorical_threshold.\n",
      "- Converting 'age' to strings then setting type to category.\n",
      "\n",
      "'hdlngth' auto added to num_cols, due to not being an object or categorical type.\n",
      "- Converting 'hdlngth' to floats.\n",
      "\n",
      "'skullw' auto added to num_cols, due to not being an object or categorical type.\n",
      "- Converting 'skullw' to floats.\n",
      "\n",
      "'totlngth' auto added to num_cols, due to not being an object or categorical type.\n",
      "- Converting 'totlngth' to floats.\n",
      "\n",
      "'taill' auto added to num_cols, due to not being an object or categorical type.\n",
      "- Converting 'taill' to floats.\n",
      "\n",
      "'footlgth' auto added to num_cols, due to not being an object or categorical type.\n",
      "- Converting 'footlgth' to floats.\n",
      "\n",
      "'earconch' auto added to num_cols, due to not being an object or categorical type.\n",
      "- Converting 'earconch' to floats.\n",
      "\n",
      "'eye' auto added to num_cols, due to not being an object or categorical type.\n",
      "- Converting 'eye' to floats.\n",
      "\n",
      "'chest' auto added to num_cols, due to not being an object or categorical type.\n",
      "- Converting 'chest' to floats.\n",
      "\n",
      "'belly' auto added to num_cols, due to not being an object or categorical type.\n",
      "- Converting 'belly' to floats.\n",
      "\n",
      "'target' auto added to cat_cols, due to passing categorical_threshold.\n",
      "- Converting 'target' to strings then setting type to category.\n",
      "\n",
      "Optimizing model: rf using Genetic Algorithm\n",
      "[rf] Evaluating: [754, 17, 2, 5, None, True, None] | Score: 0.9610\n",
      "[rf] Evaluating: [854, 16, 10, 2, 'log2', False, None] | Score: 0.9710\n",
      "[rf] Evaluating: [130, 15, 5, 4, 'log2', True, 0.99] | Score: 0.9610\n",
      "[rf] Evaluating: [303, 44, 8, 4, 'sqrt', False, None] | Score: 0.9710\n",
      "[rf] Evaluating: [877, 20, 8, 6, 'sqrt', True, None] | Score: 0.9610\n",
      "[rf] Evaluating: [881, 31, 3, 2, 'sqrt', True, 0.9] | Score: 0.9710\n",
      "[rf] Evaluating: [967, 32, 6, 1, 'log2', False, 0.99] | Score: 0.9610\n",
      "[rf] Evaluating: [227, 34, 3, 5, 'log2', False, 0.99] | Score: 0.9610\n",
      "[rf] Evaluating: [296, 14, 2, 4, 'sqrt', True, None] | Score: 0.9710\n",
      "gen\tnevals\n",
      "0  \t9     \n",
      "Before crossover:\n",
      "  Parent1: [854, 16, 10, 2, 'log2', False, None]\n",
      "  Parent2: [881, 31, 3, 2, 'sqrt', True, 0.9]\n",
      "After crossover:\n",
      "  Child1: [854, 16, 10, 2, 'log2', True, 0.9]\n",
      "  Child2: [881, 31, 3, 2, 'sqrt', False, None]\n",
      "Before crossover:\n",
      "  Parent1: [881, 31, 3, 2, 'sqrt', True, 0.9]\n",
      "  Parent2: [854, 16, 10, 2, 'log2', False, None]\n",
      "After crossover:\n",
      "  Child1: [881, 31, 3, 2, 'log2', False, 0.9]\n",
      "  Child2: [854, 16, 10, 2, 'sqrt', True, None]\n",
      "Before crossover:\n",
      "  Parent1: [296, 14, 2, 4, 'sqrt', True, None]\n",
      "  Parent2: [227, 34, 3, 5, 'log2', False, 0.99]\n",
      "After crossover:\n",
      "  Child1: [296, 14, 2, 4, 'log2', False, None]\n",
      "  Child2: [227, 34, 3, 5, 'sqrt', True, 0.99]\n",
      "Before crossover:\n",
      "  Parent1: [296, 14, 2, 4, 'sqrt', True, None]\n",
      "  Parent2: [303, 44, 8, 4, 'sqrt', False, None]\n",
      "After crossover:\n",
      "  Child1: [296, 14, 8, 4, 'sqrt', True, None]\n",
      "  Child2: [303, 44, 2, 4, 'sqrt', False, None]\n",
      "[rf] Before mutation: [303, 44, 2, 4, 'sqrt', False, None]\n",
      "[rf] After mutation: [220, 44, 2, 4, None, False, 0.99]\n",
      "[rf] Before mutation: [881, 31, 3, 2, 'sqrt', True, 0.9]\n",
      "[rf] After mutation: [759, 42, 2, 2, None, True, 0.99]\n",
      "[rf] Evaluating: [854, 16, 10, 2, 'log2', True, 0.9] | Score: 0.9710\n",
      "[rf] Evaluating: [881, 31, 3, 2, 'sqrt', False, None] | Score: 0.9710\n",
      "[rf] Evaluating: [881, 31, 3, 2, 'log2', False, 0.9] | Score: 0.9810\n",
      "[rf] Evaluating: [854, 16, 10, 2, 'sqrt', True, None] | Score: 0.9710\n",
      "[rf] Evaluating: [296, 14, 2, 4, 'log2', False, None] | Score: 0.9710\n",
      "[rf] Evaluating: [227, 34, 3, 5, 'sqrt', True, 0.99] | Score: 0.9610\n",
      "[rf] Evaluating: [296, 14, 8, 4, 'sqrt', True, None] | Score: 0.9710\n",
      "[rf] Evaluating: [220, 44, 2, 4, None, False, 0.99] | Score: 0.9329\n",
      "[rf] Evaluating: [759, 42, 2, 2, None, True, 0.99] | Score: 0.9610\n",
      "1  \t9     \n",
      "Before crossover:\n",
      "  Parent1: [881, 31, 3, 2, 'log2', False, 0.9]\n",
      "  Parent2: [854, 16, 10, 2, 'log2', True, 0.9]\n",
      "After crossover:\n",
      "  Child1: [881, 16, 10, 2, 'log2', False, 0.9]\n",
      "  Child2: [854, 31, 3, 2, 'log2', True, 0.9]\n",
      "[rf] Before mutation: [881, 31, 3, 2, 'log2', False, 0.9]\n",
      "[rf] After mutation: [863, 31, 3, 1, None, False, 0.99]\n",
      "[rf] Before mutation: [881, 31, 3, 2, 'log2', False, 0.9]\n",
      "[rf] After mutation: [814, 30, 5, 2, 'log2', True, 0.99]\n",
      "[rf] Evaluating: [863, 31, 3, 1, None, False, 0.99] | Score: 0.9605\n",
      "[rf] Evaluating: [814, 30, 5, 2, 'log2', True, 0.99] | Score: 0.9610\n",
      "[rf] Evaluating: [881, 16, 10, 2, 'log2', False, 0.9] | Score: 0.9710\n",
      "[rf] Evaluating: [854, 31, 3, 2, 'log2', True, 0.9] | Score: 0.9710\n",
      "2  \t4     \n",
      "Before crossover:\n",
      "  Parent1: [854, 16, 10, 2, 'log2', True, 0.9]\n",
      "  Parent2: [296, 14, 2, 4, 'log2', False, None]\n",
      "After crossover:\n",
      "  Child1: [854, 14, 2, 4, 'log2', False, None]\n",
      "  Child2: [296, 16, 10, 2, 'log2', True, 0.9]\n",
      "Before crossover:\n",
      "  Parent1: [881, 31, 3, 2, 'sqrt', False, None]\n",
      "  Parent2: [881, 31, 3, 2, 'log2', False, 0.9]\n",
      "After crossover:\n",
      "  Child1: [881, 31, 3, 2, 'log2', False, None]\n",
      "  Child2: [881, 31, 3, 2, 'sqrt', False, 0.9]\n",
      "Before crossover:\n",
      "  Parent1: [881, 31, 3, 2, 'sqrt', False, None]\n",
      "  Parent2: [854, 16, 10, 2, 'log2', True, 0.9]\n",
      "After crossover:\n",
      "  Child1: [881, 16, 10, 2, 'log2', True, None]\n",
      "  Child2: [854, 31, 3, 2, 'sqrt', False, 0.9]\n",
      "[rf] Before mutation: [854, 14, 2, 4, 'log2', False, None]\n",
      "[rf] After mutation: [817, 16, 2, 4, None, False, None]\n",
      "[rf] Evaluating: [817, 16, 2, 4, None, False, None] | Score: 0.9324\n",
      "[rf] Evaluating: [296, 16, 10, 2, 'log2', True, 0.9] | Score: 0.9710\n",
      "[rf] Evaluating: [881, 31, 3, 2, 'log2', False, None] | Score: 0.9710\n",
      "[rf] Evaluating: [881, 31, 3, 2, 'sqrt', False, 0.9] | Score: 0.9710\n",
      "[rf] Evaluating: [881, 16, 10, 2, 'log2', True, None] | Score: 0.9710\n",
      "[rf] Evaluating: [854, 31, 3, 2, 'sqrt', False, 0.9] | Score: 0.9710\n",
      "3  \t6     \n",
      "Before crossover:\n",
      "  Parent1: [881, 31, 3, 2, 'log2', False, 0.9]\n",
      "  Parent2: [881, 31, 3, 2, 'log2', False, 0.9]\n",
      "After crossover:\n",
      "  Child1: [881, 31, 3, 2, 'log2', False, 0.9]\n",
      "  Child2: [881, 31, 3, 2, 'log2', False, 0.9]\n",
      "Before crossover:\n",
      "  Parent1: [881, 16, 10, 2, 'log2', True, None]\n",
      "  Parent2: [881, 16, 10, 2, 'log2', True, None]\n",
      "After crossover:\n",
      "  Child1: [881, 16, 10, 2, 'log2', True, None]\n",
      "  Child2: [881, 16, 10, 2, 'log2', True, None]\n",
      "Before crossover:\n",
      "  Parent1: [881, 31, 3, 2, 'log2', False, None]\n",
      "  Parent2: [881, 16, 10, 2, 'log2', True, None]\n",
      "After crossover:\n",
      "  Child1: [881, 31, 3, 2, 'log2', True, None]\n",
      "  Child2: [881, 16, 10, 2, 'log2', False, None]\n",
      "[rf] Before mutation: [296, 16, 10, 2, 'log2', True, 0.9]\n",
      "[rf] After mutation: [199, 16, 10, 2, None, False, None]\n",
      "[rf] Before mutation: [881, 31, 3, 2, 'log2', True, None]\n",
      "[rf] After mutation: [944, 34, 3, 2, 'sqrt', True, 0.99]\n",
      "[rf] Skipping duplicate evaluation: [881, 31, 3, 2, 'log2', False, 0.9], score reused: 0.9810\n",
      "[rf] Skipping duplicate evaluation: [881, 31, 3, 2, 'log2', False, 0.9], score reused: 0.9810\n",
      "[rf] Evaluating: [199, 16, 10, 2, None, False, None] | Score: 0.9510\n",
      "[rf] Skipping duplicate evaluation: [881, 16, 10, 2, 'log2', True, None], score reused: 0.9710\n",
      "[rf] Skipping duplicate evaluation: [881, 16, 10, 2, 'log2', True, None], score reused: 0.9710\n",
      "[rf] Evaluating: [944, 34, 3, 2, 'sqrt', True, 0.99] | Score: 0.9610\n",
      "[rf] Evaluating: [881, 16, 10, 2, 'log2', False, None] | Score: 0.9710\n",
      "4  \t7     \n",
      "Optimizing model: xgb using Genetic Algorithm\n",
      "[xgb] Evaluating: [505, 18, 0.20479016465839167, 0.7199988319195049, 0.658088598135927, 0.7518644924144021, 0.7254311449315731, 4.5828552261858615, 0.99] | Score: nan\n",
      "[xgb] Evaluating: [202, 14, 0.16591397718947193, 0.8023538776195062, 0.5662282851832336, 0.34900883496451507, 0.6879131406001926, 2.442844165081314, 0.9] | Score: nan\n",
      "[xgb] Evaluating: [261, 38, 0.251786036845544, 0.8814159700349484, 0.805838882862975, 0.9872330636315043, 6.539763177107326, 0.07823107152157949, 0.99] | Score: nan\n",
      "[xgb] Evaluating: [406, 16, 0.28228970113886015, 0.6537164457573471, 0.557714335209551, 0.10703597770941764, 5.532236408848159, 2.7234821231481634, 0.99] | Score: nan\n",
      "[xgb] Evaluating: [315, 31, 0.06904322057496134, 0.8536951835540318, 0.6319919508152048, 0.48853185214937656, 9.053364910793233, 8.461037132948555, None] | Score: nan\n",
      "[xgb] Evaluating: [749, 37, 0.25051094591794354, 0.61763470471962, 0.6667782693025441, 0.13081966070170226, 9.79797953828836, 1.6158197627388615, 0.9] | Score: nan\n",
      "[xgb] Evaluating: [664, 37, 0.17266299078467645, 0.6447495522357339, 0.9725254695233195, 0.6910196237558764, 1.490542854785195, 0.36028138060830606, 0.9] | Score: nan\n",
      "[xgb] Evaluating: [696, 45, 0.05294719781456997, 0.6509782077128555, 0.6541291749650668, 0.89898148874259, 7.9612230488804165, 8.607025820009028, 0.9] | Score: nan\n",
      "[xgb] Evaluating: [315, 25, 0.20341068908430746, 0.7414714538458473, 0.7799417595719349, 0.8747127235410912, 9.73837022637289, 7.494776111435392, None] | Score: nan\n",
      "gen\tnevals\n",
      "0  \t9     \n",
      "Before crossover:\n",
      "  Parent1: [315, 31, 0.06904322057496134, 0.8536951835540318, 0.6319919508152048, 0.48853185214937656, 9.053364910793233, 8.461037132948555, None]\n",
      "  Parent2: [664, 37, 0.17266299078467645, 0.6447495522357339, 0.9725254695233195, 0.6910196237558764, 1.490542854785195, 0.36028138060830606, 0.9]\n",
      "After crossover:\n",
      "  Child1: [315, 31, 0.06904322057496134, 0.8536951835540318, 0.6319919508152048, 0.48853185214937656, 9.053364910793233, 0.36028138060830606, 0.9]\n",
      "  Child2: [664, 37, 0.17266299078467645, 0.6447495522357339, 0.9725254695233195, 0.6910196237558764, 1.490542854785195, 8.461037132948555, None]\n",
      "[xgb] Before mutation: [749, 37, 0.25051094591794354, 0.61763470471962, 0.6667782693025441, 0.13081966070170226, 9.79797953828836, 1.6158197627388615, 0.9]\n",
      "[xgb] After mutation: [776, 35, 0.2254458447078836, 0.6, 0.7976451285991369, 0.16289727159950076, 8.804051593978553, 3.0648440701868953, 0.9]\n",
      "[xgb] Before mutation: [202, 14, 0.16591397718947193, 0.8023538776195062, 0.5662282851832336, 0.34900883496451507, 0.6879131406001926, 2.442844165081314, 0.9]\n",
      "[xgb] After mutation: [257, 12, 0.16277185933315955, 0.6407842212531203, 0.5207075468915819, 0.2654267649222973, 2.0248059048839497, 3.071669472004257, 0.9]\n",
      "[xgb] Evaluating: [776, 35, 0.2254458447078836, 0.6, 0.7976451285991369, 0.16289727159950076, 8.804051593978553, 3.0648440701868953, 0.9] | Score: nan\n",
      "[xgb] Evaluating: [315, 31, 0.06904322057496134, 0.8536951835540318, 0.6319919508152048, 0.48853185214937656, 9.053364910793233, 0.36028138060830606, 0.9] | Score: nan\n",
      "[xgb] Evaluating: [664, 37, 0.17266299078467645, 0.6447495522357339, 0.9725254695233195, 0.6910196237558764, 1.490542854785195, 8.461037132948555, None] | Score: nan\n",
      "[xgb] Evaluating: [257, 12, 0.16277185933315955, 0.6407842212531203, 0.5207075468915819, 0.2654267649222973, 2.0248059048839497, 3.071669472004257, 0.9] | Score: nan\n",
      "1  \t4     \n",
      "[xgb] Before mutation: [257, 12, 0.16277185933315955, 0.6407842212531203, 0.5207075468915819, 0.2654267649222973, 2.0248059048839497, 3.071669472004257, 0.9]\n",
      "[xgb] After mutation: [291, 11, 0.1560547504024269, 0.8091412878693656, 0.5392003603778753, 0.2900098681669539, 3.392495340616941, 2.933153854693513, None]\n",
      "[xgb] Evaluating: [291, 11, 0.1560547504024269, 0.8091412878693656, 0.5392003603778753, 0.2900098681669539, 3.392495340616941, 2.933153854693513, None] | Score: nan\n",
      "2  \t1     \n",
      "Before crossover:\n",
      "  Parent1: [664, 37, 0.17266299078467645, 0.6447495522357339, 0.9725254695233195, 0.6910196237558764, 1.490542854785195, 8.461037132948555, None]\n",
      "  Parent2: [406, 16, 0.28228970113886015, 0.6537164457573471, 0.557714335209551, 0.10703597770941764, 5.532236408848159, 2.7234821231481634, 0.99]\n",
      "After crossover:\n",
      "  Child1: [664, 37, 0.17266299078467645, 0.6447495522357339, 0.557714335209551, 0.6910196237558764, 1.490542854785195, 8.461037132948555, None]\n",
      "  Child2: [406, 16, 0.28228970113886015, 0.6537164457573471, 0.9725254695233195, 0.10703597770941764, 5.532236408848159, 2.7234821231481634, 0.99]\n",
      "[xgb] Evaluating: [664, 37, 0.17266299078467645, 0.6447495522357339, 0.557714335209551, 0.6910196237558764, 1.490542854785195, 8.461037132948555, None] | Score: nan\n",
      "[xgb] Evaluating: [406, 16, 0.28228970113886015, 0.6537164457573471, 0.9725254695233195, 0.10703597770941764, 5.532236408848159, 2.7234821231481634, 0.99] | Score: nan\n",
      "3  \t2     \n",
      "Before crossover:\n",
      "  Parent1: [664, 37, 0.17266299078467645, 0.6447495522357339, 0.9725254695233195, 0.6910196237558764, 1.490542854785195, 0.36028138060830606, 0.9]\n",
      "  Parent2: [664, 37, 0.17266299078467645, 0.6447495522357339, 0.557714335209551, 0.6910196237558764, 1.490542854785195, 8.461037132948555, None]\n",
      "After crossover:\n",
      "  Child1: [664, 37, 0.17266299078467645, 0.6447495522357339, 0.557714335209551, 0.6910196237558764, 1.490542854785195, 0.36028138060830606, 0.9]\n",
      "  Child2: [664, 37, 0.17266299078467645, 0.6447495522357339, 0.9725254695233195, 0.6910196237558764, 1.490542854785195, 8.461037132948555, None]\n",
      "[xgb] Before mutation: [664, 37, 0.17266299078467645, 0.6447495522357339, 0.9725254695233195, 0.6910196237558764, 1.490542854785195, 8.461037132948555, None]\n",
      "[xgb] After mutation: [626, 43, 0.16770985221565862, 0.6787228409933342, 0.9213616608649962, 0.7016519728293199, 1.3223797503852297, 8.298572961383451, 0.9]\n",
      "[xgb] Before mutation: [406, 16, 0.28228970113886015, 0.6537164457573471, 0.557714335209551, 0.10703597770941764, 5.532236408848159, 2.7234821231481634, 0.99]\n",
      "[xgb] After mutation: [316, 20, 0.28551849898705994, 0.724312574886439, 0.5062718938193472, 0.20441171395014252, 4.4570334573697865, 4.478040311117107, 0.9]\n",
      "[xgb] Before mutation: [749, 37, 0.25051094591794354, 0.61763470471962, 0.6667782693025441, 0.13081966070170226, 9.79797953828836, 1.6158197627388615, 0.9]\n",
      "[xgb] After mutation: [810, 37, 0.25979234412975905, 0.6175809533004791, 0.5644306346978631, 0, 8.82824516015108, 0.24967204409205768, None]\n",
      "[xgb] Evaluating: [626, 43, 0.16770985221565862, 0.6787228409933342, 0.9213616608649962, 0.7016519728293199, 1.3223797503852297, 8.298572961383451, 0.9] | Score: nan\n",
      "[xgb] Evaluating: [316, 20, 0.28551849898705994, 0.724312574886439, 0.5062718938193472, 0.20441171395014252, 4.4570334573697865, 4.478040311117107, 0.9] | Score: nan\n",
      "[xgb] Evaluating: [664, 37, 0.17266299078467645, 0.6447495522357339, 0.557714335209551, 0.6910196237558764, 1.490542854785195, 0.36028138060830606, 0.9] | Score: nan\n",
      "[xgb] Skipping duplicate evaluation: [664, 37, 0.17266299078467645, 0.6447495522357339, 0.9725254695233195, 0.6910196237558764, 1.490542854785195, 8.461037132948555, None], score reused: nan\n",
      "[xgb] Evaluating: [810, 37, 0.25979234412975905, 0.6175809533004791, 0.5644306346978631, 0, 8.82824516015108, 0.24967204409205768, None] | Score: nan\n",
      "4  \t5     \n",
      "Optimizing model: lgbm using Genetic Algorithm\n",
      "[lgbm] Evaluating: [304, 11, 0.19018734040998578, 25, 21, 0.7894244243784512, 0.5571947230546532, 9.477570222166518, 4.6503398343522075, 0.9] | Score: 0.9324\n",
      "[lgbm] Evaluating: [885, 33, 0.05865885157666265, 48, 100, 0.8873428914384033, 0.8888959430877164, 1.6376581016719916, 3.1103891959859986, 0.99] | Score: 0.5576\n",
      "[lgbm] Evaluating: [126, 29, 0.1769810512396001, 34, 55, 0.9765882394165238, 0.5991648885458576, 5.920978612498522, 8.305716337803183, None] | Score: 0.5576\n",
      "[lgbm] Evaluating: [204, 29, 0.2565850393357509, 48, 20, 0.9184908866400848, 0.7829662776836579, 0.4106913020613612, 5.3274524531050025, 0.99] | Score: 0.9705\n",
      "[lgbm] Evaluating: [479, 14, 0.1567286290063526, 31, 6, 0.939830250799831, 0.9111654590450291, 1.0553887064399858, 9.607875672145786, 0.99] | Score: 0.9324\n",
      "[lgbm] Evaluating: [948, 39, 0.21511950667476232, 37, 27, 0.8935181216053567, 0.9827368656190388, 2.7008239638740084, 8.08199218806756, 0.99] | Score: 0.9514\n",
      "[lgbm] Evaluating: [893, 40, 0.14481339377400726, 47, 39, 0.7289218331924473, 0.6227475845468454, 9.346218786140001, 2.789282491924702, 0.9] | Score: 0.9324\n",
      "[lgbm] Evaluating: [349, 39, 0.17525639695671344, 34, 48, 0.6114799991080359, 0.9254764181562296, 1.818398571576918, 2.12119850179739, 0.9] | Score: 0.5576\n",
      "[lgbm] Evaluating: [448, 27, 0.2652927941298854, 27, 76, 0.6040604457754708, 0.9740312888885156, 0.8561296195802126, 7.200746641041943, 0.9] | Score: 0.5576\n",
      "gen\tnevals\n",
      "0  \t9     \n",
      "Before crossover:\n",
      "  Parent1: [204, 29, 0.2565850393357509, 48, 20, 0.9184908866400848, 0.7829662776836579, 0.4106913020613612, 5.3274524531050025, 0.99]\n",
      "  Parent2: [204, 29, 0.2565850393357509, 48, 20, 0.9184908866400848, 0.7829662776836579, 0.4106913020613612, 5.3274524531050025, 0.99]\n",
      "After crossover:\n",
      "  Child1: [204, 29, 0.2565850393357509, 48, 20, 0.9184908866400848, 0.7829662776836579, 0.4106913020613612, 5.3274524531050025, 0.99]\n",
      "  Child2: [204, 29, 0.2565850393357509, 48, 20, 0.9184908866400848, 0.7829662776836579, 0.4106913020613612, 5.3274524531050025, 0.99]\n",
      "Before crossover:\n",
      "  Parent1: [948, 39, 0.21511950667476232, 37, 27, 0.8935181216053567, 0.9827368656190388, 2.7008239638740084, 8.08199218806756, 0.99]\n",
      "  Parent2: [948, 39, 0.21511950667476232, 37, 27, 0.8935181216053567, 0.9827368656190388, 2.7008239638740084, 8.08199218806756, 0.99]\n",
      "After crossover:\n",
      "  Child1: [948, 39, 0.21511950667476232, 37, 27, 0.8935181216053567, 0.9827368656190388, 2.7008239638740084, 8.08199218806756, 0.99]\n",
      "  Child2: [948, 39, 0.21511950667476232, 37, 27, 0.8935181216053567, 0.9827368656190388, 2.7008239638740084, 8.08199218806756, 0.99]\n",
      "[lgbm] Before mutation: [204, 29, 0.2565850393357509, 48, 20, 0.9184908866400848, 0.7829662776836579, 0.4106913020613612, 5.3274524531050025, 0.99]\n",
      "[lgbm] After mutation: [216, 32, 0.25730917797659997, 48, 17, 0.9014471005038747, 0.908278481410523, 0.20652154640205736, 5.158888173623707, 0.9]\n",
      "[lgbm] Before mutation: [948, 39, 0.21511950667476232, 37, 27, 0.8935181216053567, 0.9827368656190388, 2.7008239638740084, 8.08199218806756, 0.99]\n",
      "[lgbm] After mutation: [924, 43, 0.21574926901975128, 33, 27, 0.9680204176280404, 0.966328051241959, 3.018659420114798, 7.70615446363107, None]\n",
      "[lgbm] Before mutation: [948, 39, 0.21511950667476232, 37, 27, 0.8935181216053567, 0.9827368656190388, 2.7008239638740084, 8.08199218806756, 0.99]\n",
      "[lgbm] After mutation: [937, 38, 0.22273334612685589, 42, 22, 1.0, 1.0, 3.8527628111574397, 6.69345354099282, None]\n",
      "[lgbm] Skipping duplicate evaluation: [204, 29, 0.2565850393357509, 48, 20, 0.9184908866400848, 0.7829662776836579, 0.4106913020613612, 5.3274524531050025, 0.99], score reused: 0.9705\n",
      "[lgbm] Evaluating: [216, 32, 0.25730917797659997, 48, 17, 0.9014471005038747, 0.908278481410523, 0.20652154640205736, 5.158888173623707, 0.9] | Score: 0.9705\n",
      "[lgbm] Evaluating: [924, 43, 0.21574926901975128, 33, 27, 0.9680204176280404, 0.966328051241959, 3.018659420114798, 7.70615446363107, None] | Score: 0.9514\n",
      "[lgbm] Skipping duplicate evaluation: [948, 39, 0.21511950667476232, 37, 27, 0.8935181216053567, 0.9827368656190388, 2.7008239638740084, 8.08199218806756, 0.99], score reused: 0.9514\n",
      "[lgbm] Evaluating: [937, 38, 0.22273334612685589, 42, 22, 1.0, 1.0, 3.8527628111574397, 6.69345354099282, None] | Score: 0.9324\n",
      "1  \t5     \n",
      "[lgbm] Before mutation: [204, 29, 0.2565850393357509, 48, 20, 0.9184908866400848, 0.7829662776836579, 0.4106913020613612, 5.3274524531050025, 0.99]\n",
      "[lgbm] After mutation: [150, 31, 0.26399063738482925, 48, 14, 0.9061108905173784, 0.8329922256986558, 0, 3.889991205392108, 0.9]\n",
      "[lgbm] Evaluating: [150, 31, 0.26399063738482925, 48, 14, 0.9061108905173784, 0.8329922256986558, 0, 3.889991205392108, 0.9] | Score: 0.9610\n",
      "2  \t1     \n",
      "Before crossover:\n",
      "  Parent1: [216, 32, 0.25730917797659997, 48, 17, 0.9014471005038747, 0.908278481410523, 0.20652154640205736, 5.158888173623707, 0.9]\n",
      "  Parent2: [204, 29, 0.2565850393357509, 48, 20, 0.9184908866400848, 0.7829662776836579, 0.4106913020613612, 5.3274524531050025, 0.99]\n",
      "After crossover:\n",
      "  Child1: [216, 32, 0.25730917797659997, 48, 17, 0.9184908866400848, 0.7829662776836579, 0.4106913020613612, 5.158888173623707, 0.9]\n",
      "  Child2: [204, 29, 0.2565850393357509, 48, 20, 0.9014471005038747, 0.908278481410523, 0.20652154640205736, 5.3274524531050025, 0.99]\n",
      "[lgbm] Before mutation: [204, 29, 0.2565850393357509, 48, 20, 0.9184908866400848, 0.7829662776836579, 0.4106913020613612, 5.3274524531050025, 0.99]\n",
      "[lgbm] After mutation: [236, 31, 0.26942787668877166, 50, 26, 0.7783875077256985, 0.9847216076833925, 0.42528324860019073, 5.0030833165803505, 0.99]\n",
      "[lgbm] Evaluating: [236, 31, 0.26942787668877166, 50, 26, 0.7783875077256985, 0.9847216076833925, 0.42528324860019073, 5.0030833165803505, 0.99] | Score: 0.9610\n",
      "[lgbm] Evaluating: [216, 32, 0.25730917797659997, 48, 17, 0.9184908866400848, 0.7829662776836579, 0.4106913020613612, 5.158888173623707, 0.9] | Score: 0.9610\n",
      "[lgbm] Evaluating: [204, 29, 0.2565850393357509, 48, 20, 0.9014471005038747, 0.908278481410523, 0.20652154640205736, 5.3274524531050025, 0.99] | Score: 0.9705\n",
      "3  \t3     \n",
      "Before crossover:\n",
      "  Parent1: [204, 29, 0.2565850393357509, 48, 20, 0.9184908866400848, 0.7829662776836579, 0.4106913020613612, 5.3274524531050025, 0.99]\n",
      "  Parent2: [204, 29, 0.2565850393357509, 48, 20, 0.9184908866400848, 0.7829662776836579, 0.4106913020613612, 5.3274524531050025, 0.99]\n",
      "After crossover:\n",
      "  Child1: [204, 29, 0.2565850393357509, 48, 20, 0.9184908866400848, 0.7829662776836579, 0.4106913020613612, 5.3274524531050025, 0.99]\n",
      "  Child2: [204, 29, 0.2565850393357509, 48, 20, 0.9184908866400848, 0.7829662776836579, 0.4106913020613612, 5.3274524531050025, 0.99]\n",
      "Before crossover:\n",
      "  Parent1: [204, 29, 0.2565850393357509, 48, 20, 0.9184908866400848, 0.7829662776836579, 0.4106913020613612, 5.3274524531050025, 0.99]\n",
      "  Parent2: [216, 32, 0.25730917797659997, 48, 17, 0.9014471005038747, 0.908278481410523, 0.20652154640205736, 5.158888173623707, 0.9]\n",
      "After crossover:\n",
      "  Child1: [204, 29, 0.25730917797659997, 48, 17, 0.9014471005038747, 0.7829662776836579, 0.4106913020613612, 5.3274524531050025, 0.99]\n",
      "  Child2: [216, 32, 0.2565850393357509, 48, 20, 0.9184908866400848, 0.908278481410523, 0.20652154640205736, 5.158888173623707, 0.9]\n",
      "[lgbm] Before mutation: [204, 29, 0.2565850393357509, 48, 20, 0.9184908866400848, 0.7829662776836579, 0.4106913020613612, 5.3274524531050025, 0.99]\n",
      "[lgbm] After mutation: [207, 28, 0.2377377696924339, 42, 17, 0.9905573147742607, 0.7014922755006164, 0, 5.415761599488768, 0.99]\n",
      "[lgbm] Skipping duplicate evaluation: [204, 29, 0.2565850393357509, 48, 20, 0.9184908866400848, 0.7829662776836579, 0.4106913020613612, 5.3274524531050025, 0.99], score reused: 0.9705\n",
      "[lgbm] Skipping duplicate evaluation: [204, 29, 0.2565850393357509, 48, 20, 0.9184908866400848, 0.7829662776836579, 0.4106913020613612, 5.3274524531050025, 0.99], score reused: 0.9705\n",
      "[lgbm] Evaluating: [207, 28, 0.2377377696924339, 42, 17, 0.9905573147742607, 0.7014922755006164, 0, 5.415761599488768, 0.99] | Score: 0.9705\n",
      "[lgbm] Evaluating: [204, 29, 0.25730917797659997, 48, 17, 0.9014471005038747, 0.7829662776836579, 0.4106913020613612, 5.3274524531050025, 0.99] | Score: 0.9514\n",
      "[lgbm] Evaluating: [216, 32, 0.2565850393357509, 48, 20, 0.9184908866400848, 0.908278481410523, 0.20652154640205736, 5.158888173623707, 0.9] | Score: 0.9705\n",
      "4  \t5     \n",
      "\n",
      "Evaluating Stacking Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model evaluation took: 210.40 seconds.\n",
      "\n",
      "[Stacking Model Genetic Cross-Validation Results]\n",
      "- Fold 1 Score: 1.000\n",
      "- Fold 2 Score: 1.000\n",
      "- Fold 3 Score: 1.000\n",
      "- Fold 4 Score: 0.952\n",
      "- Fold 5 Score: 0.900\n",
      "- Average CV Score: 0.970\n",
      "\n",
      "Evaluation complete, fitting on all available data.\n",
      "\n",
      "New model 'possum_model.pkl' created and saved successfully.\n",
      "Pipeline structure has been saved to 'pipeline.html'.\n"
     ]
    }
   ],
   "source": [
    "# Make new or load existing stacking model\n",
    "stacking_model = make_new_or_load_existing_model(df,\n",
    "                                                 target_column=target_column,\n",
    "                                                 categorical_threshold=categorical_threshold,\n",
    "                                                 model_name=model_name, \n",
    "                                                 load_existing_model=load_existing_model, \n",
    "                                                 problem_type=problem_type, \n",
    "                                                 n_folds=n_folds, \n",
    "                                                 n_population=n_population, \n",
    "                                                 n_generations=n_generations, \n",
    "                                                 cxpb=cxpb, \n",
    "                                                 mutpb=mutpb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2e3e8b",
   "metadata": {
    "papermill": {
     "duration": 0.018586,
     "end_time": "2024-12-30T07:33:13.361550",
     "exception": false,
     "start_time": "2024-12-30T07:33:13.342964",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PERMUTATION FEATURE IMPORTANCE CV\n",
    "### (Final Estimator In Stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e343b15",
   "metadata": {
    "papermill": {
     "duration": 0.018278,
     "end_time": "2024-12-30T07:33:13.398338",
     "exception": false,
     "start_time": "2024-12-30T07:33:13.380060",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"border:2px solid #FF69B4; padding: 10px; border-radius: 10px; background-color: #FFD1DC;\">\n",
    "    <h3 style=\"color: #FF1493; text-align: center;\">Reminder: Adjust Permutation Feature Importance Settings</h3>\n",
    "    <p style=\"font-size: 14px; color: #4B0082; text-align: center;\">\n",
    "        Before proceeding, please make sure to review and adjust the following settings in the <strong>SET IMPORTANT VARIABLES</strong> section of this notebook as needed:\n",
    "    </p>\n",
    "    <ul style=\"font-size: 14px; color: #4B0082;\">\n",
    "        <li><strong>target_column</strong>: The target column in your dataset.</li>\n",
    "        <li><strong>get_permutation_importance</strong>: Decide whether to show permutation importance.</li>\n",
    "        <li><strong>model</strong>: The model used for generating permutation importance plots.</li>\n",
    "        <li><strong>n_folds</strong>: Set the number of folds for cross-validation.</li>\n",
    "        <li><strong>seed_value</strong>: For reproducibility.</li>\n",
    "        <li><strong>n_repeats</strong>: Set the number of times to repeat the permutation importance calculation. This will be validated by the same number of folds in <code>n_folds</code>.</li>\n",
    "        <li><strong>colorscale</strong>: Optionally control the colorscale to be used for the plot (e.g., 'Inferno'). This setting is not actually in SET IMPORTANT VARIABLES since it's not important so you will need to set it here.</li>\n",
    "    </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49544174",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T22:09:17.687489Z",
     "start_time": "2024-08-26T22:08:50.206292Z"
    },
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-12-30T07:33:13.438565Z",
     "iopub.status.busy": "2024-12-30T07:33:13.438139Z",
     "iopub.status.idle": "2024-12-30T07:34:37.687538Z",
     "shell.execute_reply": "2024-12-30T07:34:37.686036Z"
    },
    "papermill": {
     "duration": 84.29105,
     "end_time": "2024-12-30T07:34:37.708798",
     "exception": false,
     "start_time": "2024-12-30T07:33:13.417748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"900\"\n",
       "            src=\"permutation_fig_3d.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ace3cc1fc90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Perform n_folds cross-validation using the stacking model while permutating each feature n_repeats times to determine most important features\n",
    "permutation_fig_3d = get_permutation_importance_plots(df=df, \n",
    "                                                      target_column=target_column,\n",
    "                                                      get_permutation_importance=get_permutation_importance, \n",
    "                                                      model=stacking_model, \n",
    "                                                      n_folds=n_folds, \n",
    "                                                      seed_value=seed_value, \n",
    "                                                      n_repeats=n_repeats, \n",
    "                                                      colorscale='Inferno')\n",
    "\n",
    "# Assuming permutation_fig_3d is returned from the function\n",
    "if permutation_fig_3d is not None:\n",
    "    # Save the figure as an HTML file\n",
    "    permutation_fig_3d.write_html('permutation_fig_3d.html')\n",
    "\n",
    "    # Display the saved HTML file in a notebook\n",
    "    display(IFrame('permutation_fig_3d.html', width=900, height=900))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1534513,
     "sourceId": 2532158,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30387,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 356.405355,
   "end_time": "2024-12-30T07:34:40.350927",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-30T07:28:43.945572",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2501459354fb432097ca1f83467d7f89": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a54ca23f1a7b412faef364db8bbfe1f2",
       "placeholder": "​",
       "style": "IPY_MODEL_bb24ceb56f8245e7afbc2d72543d6701",
       "value": "Done! Use &#x27;show&#x27; commands to display/save.   "
      }
     },
     "406b00e9c75a47f8b8f052fcba6c71b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "48a2d95c003644f2940eb74c74ffbfe9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4d0fb5ccc5764b6c8bfa9c40835fef64": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "66ebb1f0f6d94668b3a34d1cafcf8dc4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "75987adf87e847f0a134cead01e5698d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7f67f71d1445417e82fffdbe15f9a0c5",
       "placeholder": "​",
       "style": "IPY_MODEL_4d0fb5ccc5764b6c8bfa9c40835fef64",
       "value": " [100%]   00:01 -&gt; (00:00 left)"
      }
     },
     "7f67f71d1445417e82fffdbe15f9a0c5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8c768e07963b4b53820dd6ef3c9bc465": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_48a2d95c003644f2940eb74c74ffbfe9",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_66ebb1f0f6d94668b3a34d1cafcf8dc4",
       "value": 1.0
      }
     },
     "a54ca23f1a7b412faef364db8bbfe1f2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b206e1009e07477e8b9729825118bc35": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2501459354fb432097ca1f83467d7f89",
        "IPY_MODEL_8c768e07963b4b53820dd6ef3c9bc465",
        "IPY_MODEL_75987adf87e847f0a134cead01e5698d"
       ],
       "layout": "IPY_MODEL_406b00e9c75a47f8b8f052fcba6c71b1"
      }
     },
     "bb24ceb56f8245e7afbc2d72543d6701": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
